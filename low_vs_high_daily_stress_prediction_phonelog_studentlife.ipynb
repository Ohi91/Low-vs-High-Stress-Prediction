{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89fb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13de8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/ohidabinteamin/Documents/Stress Prediction Project Three Datasets/StudentLife/week 01/PhoneLog/raw_phonelog_features_studentlife.csv')\n",
    "df1 = df1.rename(columns={'Date': 'date'})\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df2 = pd.read_csv('/Users/ohidabinteamin/Documents/Stress Prediction Project Three Datasets/StudentLife/week 01/Stress/recreating_dailystress_features.csv')\n",
    "df2 = df2.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8790dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'uid', 'morning_phonecharge_duration',\n",
      "       'morning_phonecharge_frequency', 'morning_phonelock_duration',\n",
      "       'morning_phonelock_frequency', 'morning_dark_duration',\n",
      "       'afternoon_phonecharge_duration', 'afternoon_phonecharge_frequency',\n",
      "       'afternoon_phonelock_duration', 'afternoon_phonelock_frequency',\n",
      "       'afternoon_dark_duration', 'evening_phonecharge_duration',\n",
      "       'evening_phonecharge_frequency', 'evening_phonelock_duration',\n",
      "       'evening_phonelock_frequency', 'evening_dark_duration',\n",
      "       'night_phonecharge_duration', 'night_phonecharge_frequency',\n",
      "       'night_phonelock_duration', 'night_phonelock_frequency',\n",
      "       'night_dark_duration', 'stress_ratings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df1, df2, on=['uid', 'date'])\n",
    "print(df.columns)\n",
    "\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576bb6e1-ad0a-4d6c-9768-5a7a30b1dfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3349\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2f78a1-7383-4c8c-846c-06763e97ab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'uid', 'morning_phonecharge_duration',\n",
       "       'morning_phonecharge_frequency', 'morning_phonelock_duration',\n",
       "       'morning_phonelock_frequency', 'morning_dark_duration',\n",
       "       'afternoon_phonecharge_duration', 'afternoon_phonecharge_frequency',\n",
       "       'afternoon_phonelock_duration', 'afternoon_phonelock_frequency',\n",
       "       'afternoon_dark_duration', 'evening_phonecharge_duration',\n",
       "       'evening_phonecharge_frequency', 'evening_phonelock_duration',\n",
       "       'evening_phonelock_frequency', 'evening_dark_duration',\n",
       "       'night_phonecharge_duration', 'night_phonecharge_frequency',\n",
       "       'night_phonelock_duration', 'night_phonelock_frequency',\n",
       "       'night_dark_duration', 'stress_ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637f66c7-2809-40a4-abc0-702c72e594a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stress_ratings\n",
       "medium stress    1328\n",
       "high stress      1043\n",
       "low stress        978\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stress_ratings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05191acb-7624-4e48-9767-a3052e486aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lh_data = df[df['stress_ratings'].isin(['low stress', 'high stress'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3a31f1-a8e0-4bba-8ef1-d18f29836618",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = binary_lh_data.drop(columns=['stress_ratings', 'uid', 'date'])\n",
    "y = binary_lh_data['stress_ratings']\n",
    "groups = binary_lh_data['uid']\n",
    "\n",
    "stress_map = {'low stress': 0, 'high stress': 1}\n",
    "y_encoded = y.map(stress_map).values \n",
    "\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30d3ea7-b395-4fcf-ad12-0d03a5fecbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "best_thresholds = []\n",
    "balanced_accs = []\n",
    "auc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7701e78-71b0-4f7c-a2cc-4f7e9f5df8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2c457a-8b68-42c8-926e-86cf5e2be7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:   0%|                                    | 0/43 [00:00<?]   0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y train shapes: \n",
      "(1950, 20)\n",
      "(1950,)\n",
      "Train set - Class 0 (Low Stress): 948, Class 1 (High Stress): 1002\n",
      "Test set - Class 0 (Low Stress): 30, Class 1 (High Stress): 41\n",
      "Test set size: 71\n",
      "Train set shape: (1950, 20)\n",
      "Test set shape: (71, 20)\n",
      "(1950, 20)\n",
      "(71, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0284810126582278, 1: 0.9730538922155688}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 10:56:26.530665: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 1s 1ms/step - loss: 0.6961 - accuracy: 0.5108\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4985\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5046\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5103\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5164\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5046\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5108\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5154\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5138\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5164\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5072\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5138\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5200\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5031\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5138\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5169\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5149\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5164\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5077\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5246\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5123\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5185\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5338\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5169\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5241\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5272\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5272\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5179\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5103\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5236\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5349\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5236\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5267\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5287\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5303\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5277\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5374\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5297\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5231\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5267\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5400\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5400\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5446\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5297\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5313\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5421\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5338\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5215\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5344\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5297\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5221\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5277\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5354\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5323\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5323\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5277\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5405\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5390\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5277\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5323\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5292\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5374\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5354\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5359\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5405\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5328\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5390\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 731us/step - loss: 0.6845 - accuracy: 0.5323\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 450us/step - loss: 0.6856 - accuracy: 0.5318\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 437us/step - loss: 0.6851 - accuracy: 0.5364\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 434us/step - loss: 0.6856 - accuracy: 0.5338\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6831 - accuracy: 0.5441\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 425us/step - loss: 0.6800 - accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 429us/step - loss: 0.6841 - accuracy: 0.5349\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 433us/step - loss: 0.6862 - accuracy: 0.5308\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 457us/step - loss: 0.6830 - accuracy: 0.5385\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 441us/step - loss: 0.6830 - accuracy: 0.5477\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 451us/step - loss: 0.6802 - accuracy: 0.5426\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 459us/step - loss: 0.6845 - accuracy: 0.5308\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 451us/step - loss: 0.6822 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 465us/step - loss: 0.6849 - accuracy: 0.5364\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 456us/step - loss: 0.6805 - accuracy: 0.5421\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 450us/step - loss: 0.6824 - accuracy: 0.5451\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 437us/step - loss: 0.6824 - accuracy: 0.5451\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 449us/step - loss: 0.6844 - accuracy: 0.5374\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 430us/step - loss: 0.6827 - accuracy: 0.5441\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 538us/step - loss: 0.6793 - accuracy: 0.5528\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5405\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5328\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5354\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5415\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5523\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5354\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5518\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5415\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5492\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5477\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5405\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5446\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "<0.5 AUC Score: 0.47439024390243895\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5121951219512195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:   2%|▋                               | 1/43 [00:09<06:30]   2%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y train shapes: \n",
      "(1978, 20)\n",
      "(1978,)\n",
      "Train set - Class 0 (Low Stress): 952, Class 1 (High Stress): 1026\n",
      "Test set - Class 0 (Low Stress): 26, Class 1 (High Stress): 17\n",
      "Test set size: 43\n",
      "Train set shape: (1978, 20)\n",
      "Test set shape: (43, 20)\n",
      "(1978, 20)\n",
      "(43, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0388655462184875, 1: 0.9639376218323586}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.4772\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4752\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4853\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4863\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4843\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5147\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4944\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5076\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5056\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5207\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5121\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5035\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5313\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5035\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5197\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5086\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5273\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5116\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5253\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5207\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5278\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5157\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5379\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5192\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5217\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5379\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5142\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5369\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5288\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5389\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5364\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5248\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5288\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5389\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5349\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5465\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5349\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5344\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5425\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5480\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5354\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5440\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5399\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5369\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5576\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5455\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5465\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5475\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5511\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5379\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5374\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5521\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5364\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5364\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5698\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5450\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5379\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5592\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5566\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5420\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 855us/step - loss: 0.6828 - accuracy: 0.5576\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 572us/step - loss: 0.6858 - accuracy: 0.5465\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6834 - accuracy: 0.5516\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.6841 - accuracy: 0.5384\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6854 - accuracy: 0.5602\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.6853 - accuracy: 0.5445\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.6860 - accuracy: 0.5521\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.6859 - accuracy: 0.5511\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 455us/step - loss: 0.6836 - accuracy: 0.5445\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6862 - accuracy: 0.5420\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6855 - accuracy: 0.5475\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 463us/step - loss: 0.6848 - accuracy: 0.5506\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 465us/step - loss: 0.6826 - accuracy: 0.5627\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 443us/step - loss: 0.6818 - accuracy: 0.5541\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.6806 - accuracy: 0.5597\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6822 - accuracy: 0.5617\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6835 - accuracy: 0.5708\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 459us/step - loss: 0.6827 - accuracy: 0.5521\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5688\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5536\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5531\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5718\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5430\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5662\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5571\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5703\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5672\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5546\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.5733\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5708\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5637\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5718\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5662\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5576\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5622\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5885\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5521\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5612\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5551\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5662\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:   5%|█▍                              | 2/43 [00:20<06:55]   5%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5169683257918551\n",
      "Balanced Accuracy: 0.5316742081447964\n",
      "X and y train shapes: \n",
      "(1981, 20)\n",
      "(1981,)\n",
      "Train set - Class 0 (Low Stress): 955, Class 1 (High Stress): 1026\n",
      "Test set - Class 0 (Low Stress): 23, Class 1 (High Stress): 17\n",
      "Test set size: 40\n",
      "Train set shape: (1981, 20)\n",
      "Test set shape: (40, 20)\n",
      "(1981, 20)\n",
      "(40, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.03717277486911, 1: 0.9653996101364523}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.4891\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5103\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 658us/step - loss: 0.6981 - accuracy: 0.5124\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 632us/step - loss: 0.6925 - accuracy: 0.5149\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 613us/step - loss: 0.6937 - accuracy: 0.4811\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.6949 - accuracy: 0.4947\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6933 - accuracy: 0.5053\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6929 - accuracy: 0.4861\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6931 - accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6931 - accuracy: 0.4937\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6936 - accuracy: 0.5139\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6916 - accuracy: 0.4927\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6934 - accuracy: 0.4982\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6931 - accuracy: 0.5225\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 415us/step - loss: 0.6921 - accuracy: 0.5204\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.6944 - accuracy: 0.5018\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.6929 - accuracy: 0.4841\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6915 - accuracy: 0.4907\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6920 - accuracy: 0.4937\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.6927 - accuracy: 0.4967\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.6925 - accuracy: 0.4972\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6918 - accuracy: 0.4922\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6922 - accuracy: 0.4957\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6906 - accuracy: 0.4997\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6938 - accuracy: 0.4861\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.6913 - accuracy: 0.5018\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 465us/step - loss: 0.6915 - accuracy: 0.4937\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.6916 - accuracy: 0.4987\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 458us/step - loss: 0.6887 - accuracy: 0.5038\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.6932 - accuracy: 0.5073\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.6880 - accuracy: 0.5154\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6898 - accuracy: 0.5073\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6937 - accuracy: 0.5028\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 458us/step - loss: 0.6930 - accuracy: 0.4957\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4992\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5028\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5008\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.4972\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5013\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4932\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5033\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5058\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5058\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5199\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5240\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5215\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5149\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5280\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5250\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5310\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5169\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5215\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5144\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5250\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5270\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5129\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5215\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5275\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5300\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5331\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5109\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5199\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5194\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5159\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5391\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5240\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5285\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5220\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5290\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5300\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5260\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5240\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5300\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5411\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5315\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5442\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5416\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5351\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5260\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5467\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5356\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5401\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5315\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5396\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5422\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5260\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5376\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5442\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5310\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5457\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5467\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5442\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5467\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5356\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5326\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5341\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5447\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5275\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5255\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5270\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:   7%|██▏                             | 3/43 [00:26<05:42]   7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5447570332480819\n",
      "Balanced Accuracy: 0.5588235294117647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y train shapes: \n",
      "(1924, 20)\n",
      "(1924,)\n",
      "Train set - Class 0 (Low Stress): 926, Class 1 (High Stress): 998\n",
      "Test set - Class 0 (Low Stress): 52, Class 1 (High Stress): 45\n",
      "Test set size: 97\n",
      "Train set shape: (1924, 20)\n",
      "Test set shape: (97, 20)\n",
      "(1924, 20)\n",
      "(97, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.038876889848812, 1: 0.9639278557114228}\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5016\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4927\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4922\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4979\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4927\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 947us/step - loss: 0.6933 - accuracy: 0.4932\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 653us/step - loss: 0.6922 - accuracy: 0.4932\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 474us/step - loss: 0.6939 - accuracy: 0.4782\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 433us/step - loss: 0.6934 - accuracy: 0.4880\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 405us/step - loss: 0.6939 - accuracy: 0.4849\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6929 - accuracy: 0.4844\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6933 - accuracy: 0.4849\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6938 - accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 436us/step - loss: 0.6923 - accuracy: 0.4901\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6924 - accuracy: 0.4912\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6933 - accuracy: 0.4870\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 439us/step - loss: 0.6921 - accuracy: 0.4901\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 429us/step - loss: 0.6910 - accuracy: 0.5010\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6926 - accuracy: 0.4875\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6924 - accuracy: 0.4932\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6910 - accuracy: 0.4922\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 432us/step - loss: 0.6921 - accuracy: 0.4958\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 433us/step - loss: 0.6930 - accuracy: 0.4901\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 423us/step - loss: 0.6912 - accuracy: 0.4984\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6917 - accuracy: 0.4953\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 550us/step - loss: 0.6909 - accuracy: 0.4896\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.4948\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4974\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4927\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4958\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5010\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4932\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.4990\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4849\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4891\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.4990\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5026\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4886\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4969\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5026\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5078\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5114\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5036\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5068\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.4953\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5026\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.4912\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.4891\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.4958\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5135\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5125\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5442\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5327\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5244\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5379\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5468\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5208\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5385\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5463\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5265\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5457\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5374\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5556\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5249\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5369\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5353\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5405\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5431\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5556\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5203\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5442\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5385\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5411\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5473\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5431\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5421\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5447\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5624\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5582\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5442\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5385\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5556\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5468\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5629\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5452\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5504\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5431\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5369\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5504\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5499\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5468\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.5629\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5499\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5608\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5489\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 929us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:   9%|██▉                             | 4/43 [00:33<05:11]   9%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5688034188034188\n",
      "Balanced Accuracy: 0.564957264957265\n",
      "X and y train shapes: \n",
      "(2012, 20)\n",
      "(2012,)\n",
      "Train set - Class 0 (Low Stress): 975, Class 1 (High Stress): 1037\n",
      "Test set - Class 0 (Low Stress): 3, Class 1 (High Stress): 6\n",
      "Test set size: 9\n",
      "Train set shape: (2012, 20)\n",
      "Test set shape: (9, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2012, 20)\n",
      "(9, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0317948717948717, 1: 0.970106075216972}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.4990\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5075\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5119\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5060\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5104\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5149\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5159\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5005\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4955\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 936us/step - loss: 0.6938 - accuracy: 0.4945\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.6934 - accuracy: 0.4980\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 478us/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 438us/step - loss: 0.6923 - accuracy: 0.5119\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6911 - accuracy: 0.5094\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6919 - accuracy: 0.5099\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6901 - accuracy: 0.5015\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6907 - accuracy: 0.5055\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6919 - accuracy: 0.4960\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6921 - accuracy: 0.5035\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6918 - accuracy: 0.5099\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6927 - accuracy: 0.5075\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6916 - accuracy: 0.5169\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6921 - accuracy: 0.5080\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.6886 - accuracy: 0.5323\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6925 - accuracy: 0.5169\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6903 - accuracy: 0.5104\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6917 - accuracy: 0.5060\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6900 - accuracy: 0.5189\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6895 - accuracy: 0.5124\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6890 - accuracy: 0.5214\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6910 - accuracy: 0.5089\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6885 - accuracy: 0.5219\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 804us/step - loss: 0.6912 - accuracy: 0.5104\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5070\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5229\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5139\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5224\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5403\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5119\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5239\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5194\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5273\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5214\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5109\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5194\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5234\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5219\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5224\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5268\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5144\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5244\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5244\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5224\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5273\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5169\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5234\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5224\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5338\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5244\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5358\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5244\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5288\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5313\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5318\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5273\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5398\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5244\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5288\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5338\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5462\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5293\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5368\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5393\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5308\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5442\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5303\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5278\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5487\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5408\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5273\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5512\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5348\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5338\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5457\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5318\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5403\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5219\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5363\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5383\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5368\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5318\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5442\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5398\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5328\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5288\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5417\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5323\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "AUC Score: 0.5555555555555556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  12%|███▌                            | 5/43 [00:41<04:55]  12%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Accuracy: 0.6666666666666666\n",
      "X and y train shapes: \n",
      "(1982, 20)\n",
      "(1982,)\n",
      "Train set - Class 0 (Low Stress): 960, Class 1 (High Stress): 1022\n",
      "Test set - Class 0 (Low Stress): 18, Class 1 (High Stress): 21\n",
      "Test set size: 39\n",
      "Train set shape: (1982, 20)\n",
      "Test set shape: (39, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1982, 20)\n",
      "(39, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0322916666666666, 1: 0.9696673189823874}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.4904\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5126\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5227\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5116\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5182\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5192\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5116\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5126\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4965\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5071\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5061\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 702us/step - loss: 0.6927 - accuracy: 0.5066\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 682us/step - loss: 0.6927 - accuracy: 0.5015\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 669us/step - loss: 0.6936 - accuracy: 0.5010\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 506us/step - loss: 0.6914 - accuracy: 0.4975\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.6898 - accuracy: 0.5146\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6910 - accuracy: 0.5045\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6901 - accuracy: 0.5096\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6915 - accuracy: 0.5061\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6912 - accuracy: 0.5126\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.6915 - accuracy: 0.5005\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6892 - accuracy: 0.5192\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6910 - accuracy: 0.5111\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6903 - accuracy: 0.5151\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6892 - accuracy: 0.5101\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6907 - accuracy: 0.5172\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6883 - accuracy: 0.5197\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6900 - accuracy: 0.5192\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6878 - accuracy: 0.5161\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.6914 - accuracy: 0.5071\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6912 - accuracy: 0.5005\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.6882 - accuracy: 0.5272\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.6876 - accuracy: 0.5156\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6899 - accuracy: 0.5086\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6892 - accuracy: 0.5151\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6904 - accuracy: 0.5040\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.6899 - accuracy: 0.5192\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 411us/step - loss: 0.6894 - accuracy: 0.5187\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.6874 - accuracy: 0.5166\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.6876 - accuracy: 0.5227\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6861 - accuracy: 0.5101\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6869 - accuracy: 0.5166\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6856 - accuracy: 0.5212\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 500us/step - loss: 0.6887 - accuracy: 0.5111\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5197\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5242\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5146\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5262\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5182\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5192\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5146\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5262\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5146\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5187\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5232\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5257\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5283\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5126\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5288\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5318\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5409\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5207\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5373\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5182\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5227\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5222\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5237\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5161\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5267\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5177\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5328\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5217\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5222\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5212\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5232\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5313\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5358\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5303\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5318\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5323\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5434\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5237\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5308\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5399\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5353\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5303\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5358\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5277\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5272\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.5363\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5313\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5298\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5232\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5328\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5267\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5343\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  14%|████▎                           | 6/43 [00:52<05:26]  14%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5171957671957672\n",
      "Balanced Accuracy: 0.5277777777777778\n",
      "X and y train shapes: \n",
      "(1942, 20)\n",
      "(1942,)\n",
      "Train set - Class 0 (Low Stress): 926, Class 1 (High Stress): 1016\n",
      "Test set - Class 0 (Low Stress): 52, Class 1 (High Stress): 27\n",
      "Test set size: 79\n",
      "Train set shape: (1942, 20)\n",
      "Test set shape: (79, 20)\n",
      "(1942, 20)\n",
      "(79, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.048596112311015, 1: 0.9557086614173228}\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.7003 - accuracy: 0.5082\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5278\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5221\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5196\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5314\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5335\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5129\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5381\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5340\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5242\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5350\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5366\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5216\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5283\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5154\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5366\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5160\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5283\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5453\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5304\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5273\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5216\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5355\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5402\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5221\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5299\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5463\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5386\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5407\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5252\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5438\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5371\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5371\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5335\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5366\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5396\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5340\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5340\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5263\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5366\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5376\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5443\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5283\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5458\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5381\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5294\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5489\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5458\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5324\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5324\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5381\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5427\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5376\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5536\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5541\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5396\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5566\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5499\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5299\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5438\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5402\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5546\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5592\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 767us/step - loss: 0.6893 - accuracy: 0.5422\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 699us/step - loss: 0.6880 - accuracy: 0.5402\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 512us/step - loss: 0.6858 - accuracy: 0.5592\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 450us/step - loss: 0.6886 - accuracy: 0.5376\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 446us/step - loss: 0.6900 - accuracy: 0.5366\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 437us/step - loss: 0.6863 - accuracy: 0.5484\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 433us/step - loss: 0.6887 - accuracy: 0.5458\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 429us/step - loss: 0.6864 - accuracy: 0.5489\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 441us/step - loss: 0.6882 - accuracy: 0.5376\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 423us/step - loss: 0.6865 - accuracy: 0.5541\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 425us/step - loss: 0.6897 - accuracy: 0.5458\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 452us/step - loss: 0.6890 - accuracy: 0.5427\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 443us/step - loss: 0.6878 - accuracy: 0.5417\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 448us/step - loss: 0.6879 - accuracy: 0.5541\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 430us/step - loss: 0.6848 - accuracy: 0.5484\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6837 - accuracy: 0.5566\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6887 - accuracy: 0.5510\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 424us/step - loss: 0.6848 - accuracy: 0.5592\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 429us/step - loss: 0.6848 - accuracy: 0.5572\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 425us/step - loss: 0.6839 - accuracy: 0.5479\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6875 - accuracy: 0.5407\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 450us/step - loss: 0.6850 - accuracy: 0.5572\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 480us/step - loss: 0.6826 - accuracy: 0.5700\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5644\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5716\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5623\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5474\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5623\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5520\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5525\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5726\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5654\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5613\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5546\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5664\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5613\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5747\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "<0.5 AUC Score: 0.4764957264957264\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  16%|█████                           | 7/43 [00:59<04:59]  16%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.5242165242165242\n",
      "X and y train shapes: \n",
      "(2018, 20)\n",
      "(2018,)\n",
      "Train set - Class 0 (Low Stress): 978, Class 1 (High Stress): 1040\n",
      "Test set - Class 0 (Low Stress): 0, Class 1 (High Stress): 3\n",
      "Test set size: 3\n",
      "Train set shape: (2018, 20)\n",
      "Test set shape: (3, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2018, 20)\n",
      "(3, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0316973415132924, 1: 0.9701923076923077}\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.5045\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5089\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5059\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5173\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4822\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4985\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4965\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5050\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5035\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4891\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4886\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5025\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5099\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4955\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5119\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5129\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5050\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5084\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5040\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5079\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5114\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5035\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.4980\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5069\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5069\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5149\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5010\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5010\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5059\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5074\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5055\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5099\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5159\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5045\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5094\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5050\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5119\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5079\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5055\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5005\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5119\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5010\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5069\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5089\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5213\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5050\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5089\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5129\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5114\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5069\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5050\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5055\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5159\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5089\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5079\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5064\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5154\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5084\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5020\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5134\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5154\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5164\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5069\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5159\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 789us/step - loss: 0.6873 - accuracy: 0.5104\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 538us/step - loss: 0.6863 - accuracy: 0.5159\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 516us/step - loss: 0.6884 - accuracy: 0.5079\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 456us/step - loss: 0.6901 - accuracy: 0.5050\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 451us/step - loss: 0.6891 - accuracy: 0.5079\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 546us/step - loss: 0.6885 - accuracy: 0.5109\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 536us/step - loss: 0.6868 - accuracy: 0.5089\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 463us/step - loss: 0.6888 - accuracy: 0.5040\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 468us/step - loss: 0.6879 - accuracy: 0.5114\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 462us/step - loss: 0.6877 - accuracy: 0.5079\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 454us/step - loss: 0.6858 - accuracy: 0.5109\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 457us/step - loss: 0.6892 - accuracy: 0.5099\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 451us/step - loss: 0.6844 - accuracy: 0.5114\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 454us/step - loss: 0.6870 - accuracy: 0.5099\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 444us/step - loss: 0.6846 - accuracy: 0.5203\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 460us/step - loss: 0.6859 - accuracy: 0.5188\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 432us/step - loss: 0.6855 - accuracy: 0.5134\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 446us/step - loss: 0.6874 - accuracy: 0.5159\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 449us/step - loss: 0.6848 - accuracy: 0.5109\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 723us/step - loss: 0.6857 - accuracy: 0.5074\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5059\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5168\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5159\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5223\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5178\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5094\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5099\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5104\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5193\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5183\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5134\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5198\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5139\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5193\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5129\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "LOSO CV Progress:  19%|█████▊                          | 8/43 [01:06<04:43]  19%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AUC computation for this fold as y_test contains only one class: [1]\n",
      "Balanced Accuracy: 1.0\n",
      "X and y train shapes: \n",
      "(1973, 20)\n",
      "(1973,)\n",
      "Train set - Class 0 (Low Stress): 958, Class 1 (High Stress): 1015\n",
      "Test set - Class 0 (Low Stress): 20, Class 1 (High Stress): 28\n",
      "Test set size: 48\n",
      "Train set shape: (1973, 20)\n",
      "Test set shape: (48, 20)\n",
      "(1973, 20)\n",
      "(48, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.029749478079332, 1: 0.9719211822660099}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5013\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5048\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5068\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4957\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5068\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.4825\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4952\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5099\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5053\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5058\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5185\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4886\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4972\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5150\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5170\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5256\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5089\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5139\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5104\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5226\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5190\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5185\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5271\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5205\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5241\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5276\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5185\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5139\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5322\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5205\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5322\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5129\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5241\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5256\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5378\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5256\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5276\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5210\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5210\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5337\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5322\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5241\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5276\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5367\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5215\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5393\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5251\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5443\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5332\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5418\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5393\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5281\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5347\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5388\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5494\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5352\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5408\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5438\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5464\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5514\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5550\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5398\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5393\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 908us/step - loss: 0.6846 - accuracy: 0.5540\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 608us/step - loss: 0.6830 - accuracy: 0.5357\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.6833 - accuracy: 0.5383\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 468us/step - loss: 0.6824 - accuracy: 0.5438\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.6847 - accuracy: 0.5251\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.6810 - accuracy: 0.5672\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 454us/step - loss: 0.6798 - accuracy: 0.5443\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 470us/step - loss: 0.6825 - accuracy: 0.5327\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 451us/step - loss: 0.6824 - accuracy: 0.5378\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 481us/step - loss: 0.6783 - accuracy: 0.5520\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6824 - accuracy: 0.5494\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.6775 - accuracy: 0.5596\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.6816 - accuracy: 0.5403\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6865 - accuracy: 0.5383\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6812 - accuracy: 0.5357\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 443us/step - loss: 0.6826 - accuracy: 0.5327\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6821 - accuracy: 0.5378\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.6788 - accuracy: 0.5499\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.6826 - accuracy: 0.5398\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6843 - accuracy: 0.5317\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.6835 - accuracy: 0.5418\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.6793 - accuracy: 0.5378\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.6827 - accuracy: 0.5327\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 443us/step - loss: 0.6838 - accuracy: 0.5317\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.6821 - accuracy: 0.5454\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.6751 - accuracy: 0.5484\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6707 - accuracy: 0.5509\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.6774 - accuracy: 0.5479\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 471us/step - loss: 0.6823 - accuracy: 0.5373\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 872us/step - loss: 0.6719 - accuracy: 0.5565\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5540\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5454\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5499\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5540\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5555\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  21%|██████▍                         | 9/43 [01:13<04:22]  21%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5580357142857143\n",
      "Balanced Accuracy: 0.5821428571428571\n",
      "X and y train shapes: \n",
      "(1993, 20)\n",
      "(1993,)\n",
      "Train set - Class 0 (Low Stress): 965, Class 1 (High Stress): 1028\n",
      "Test set - Class 0 (Low Stress): 13, Class 1 (High Stress): 15\n",
      "Test set size: 28\n",
      "Train set shape: (1993, 20)\n",
      "Test set shape: (28, 20)\n",
      "(1993, 20)\n",
      "(28, 20)\n",
      "Model Defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weight:  {0: 1.0326424870466322, 1: 0.9693579766536965}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7072 - accuracy: 0.4777\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5093\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5103\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5018\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5138\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5043\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5213\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5203\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5058\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5273\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5138\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5143\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5163\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5093\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5289\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5228\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5289\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5203\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5198\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5243\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5208\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5278\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5278\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5068\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5248\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5314\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5273\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5294\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5188\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5188\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5309\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5258\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5319\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5309\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5148\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5329\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5314\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5319\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5113\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5404\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5409\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5304\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5354\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5379\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5389\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5379\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5379\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5173\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5299\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5409\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5339\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5349\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5499\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5474\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5419\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5334\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5314\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5504\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5404\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5289\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5374\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5419\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5374\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5499\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5454\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5469\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5529\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5414\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5384\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5464\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5590\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5454\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5544\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5569\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 952us/step - loss: 0.6867 - accuracy: 0.5469\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 667us/step - loss: 0.6849 - accuracy: 0.5549\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 499us/step - loss: 0.6853 - accuracy: 0.5419\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 491us/step - loss: 0.6853 - accuracy: 0.5484\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 542us/step - loss: 0.6814 - accuracy: 0.5524\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 564us/step - loss: 0.6836 - accuracy: 0.5610\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 540us/step - loss: 0.6860 - accuracy: 0.5544\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 459us/step - loss: 0.6836 - accuracy: 0.5449\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 474us/step - loss: 0.6865 - accuracy: 0.5494\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 478us/step - loss: 0.6841 - accuracy: 0.5479\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6838 - accuracy: 0.5414\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6859 - accuracy: 0.5384\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6822 - accuracy: 0.5539\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6857 - accuracy: 0.5434\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 436us/step - loss: 0.6828 - accuracy: 0.5569\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6830 - accuracy: 0.5580\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 438us/step - loss: 0.6862 - accuracy: 0.5439\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5484\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5444\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5459\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5600\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5650\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5529\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5690\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5725\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5575\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  23%|██████▉                        | 10/43 [01:21<04:18]  23%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.4512820512820513\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5384615384615384\n",
      "X and y train shapes: \n",
      "(2016, 20)\n",
      "(2016,)\n",
      "Train set - Class 0 (Low Stress): 976, Class 1 (High Stress): 1040\n",
      "Test set - Class 0 (Low Stress): 2, Class 1 (High Stress): 3\n",
      "Test set size: 5\n",
      "Train set shape: (2016, 20)\n",
      "Test set shape: (5, 20)\n",
      "(2016, 20)\n",
      "(5, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0327868852459017, 1: 0.9692307692307692}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.4891\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4876\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4916\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4975\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4921\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4821\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4955\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5015\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4896\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4945\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4881\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.4950\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5015\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4841\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5025\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5064\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5015\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.4921\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5050\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.4960\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4945\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4995\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5060\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4970\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5045\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5069\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5174\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5124\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5179\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5099\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5040\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5045\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5213\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5060\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5050\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5045\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.4945\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5149\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5278\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5278\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5288\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5193\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5382\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5407\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5218\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5352\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5347\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5303\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5417\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5268\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5367\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5441\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5397\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5422\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5417\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5456\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5357\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5357\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5461\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5451\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5427\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5342\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5367\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5303\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5600\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 648us/step - loss: 0.6866 - accuracy: 0.5317\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 646us/step - loss: 0.6809 - accuracy: 0.5342\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 584us/step - loss: 0.6833 - accuracy: 0.5392\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6817 - accuracy: 0.5387\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6801 - accuracy: 0.5441\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6798 - accuracy: 0.5526\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6828 - accuracy: 0.5536\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6797 - accuracy: 0.5417\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6855 - accuracy: 0.5451\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6802 - accuracy: 0.5456\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 407us/step - loss: 0.6803 - accuracy: 0.5526\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 402us/step - loss: 0.6791 - accuracy: 0.5570\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6826 - accuracy: 0.5506\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6785 - accuracy: 0.5585\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6800 - accuracy: 0.5481\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6855 - accuracy: 0.5580\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6833 - accuracy: 0.5382\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6769 - accuracy: 0.5580\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 407us/step - loss: 0.6782 - accuracy: 0.5536\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6793 - accuracy: 0.5526\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5506\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5377\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5551\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5327\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5441\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5456\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5506\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5476\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5551\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5556\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.5526\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5610\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5575\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5441\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16b3e9990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16b3e9990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  26%|███████▋                       | 11/43 [01:32<04:38]  26%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5\n",
      "Balanced Accuracy: 0.6666666666666666\n",
      "X and y train shapes: \n",
      "(1893, 20)\n",
      "(1893,)\n",
      "Train set - Class 0 (Low Stress): 899, Class 1 (High Stress): 994\n",
      "Test set - Class 0 (Low Stress): 79, Class 1 (High Stress): 49\n",
      "Test set size: 128\n",
      "Train set shape: (1893, 20)\n",
      "Test set shape: (128, 20)\n",
      "(1893, 20)\n",
      "(128, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0528364849833147, 1: 0.9522132796780685}\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.5114\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.4971\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4913\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4913\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4802\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4834\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4913\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4849\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.4992\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4960\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.4992\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4897\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.4966\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4966\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 799us/step - loss: 0.6924 - accuracy: 0.4950\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 688us/step - loss: 0.6922 - accuracy: 0.4881\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 630us/step - loss: 0.6909 - accuracy: 0.4913\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 527us/step - loss: 0.6904 - accuracy: 0.4913\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 451us/step - loss: 0.6925 - accuracy: 0.4855\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 439us/step - loss: 0.6908 - accuracy: 0.4955\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 435us/step - loss: 0.6944 - accuracy: 0.4913\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 421us/step - loss: 0.6922 - accuracy: 0.5003\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 420us/step - loss: 0.6909 - accuracy: 0.4934\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 411us/step - loss: 0.6908 - accuracy: 0.5008\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 402us/step - loss: 0.6912 - accuracy: 0.4976\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 410us/step - loss: 0.6911 - accuracy: 0.4960\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 405us/step - loss: 0.6893 - accuracy: 0.5098\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 420us/step - loss: 0.6889 - accuracy: 0.5082\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 417us/step - loss: 0.6884 - accuracy: 0.5161\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 423us/step - loss: 0.6917 - accuracy: 0.5087\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 421us/step - loss: 0.6887 - accuracy: 0.5098\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 422us/step - loss: 0.6911 - accuracy: 0.5050\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 419us/step - loss: 0.6892 - accuracy: 0.5108\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 425us/step - loss: 0.6894 - accuracy: 0.5098\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 423us/step - loss: 0.6869 - accuracy: 0.5219\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 456us/step - loss: 0.6923 - accuracy: 0.5151\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 426us/step - loss: 0.6881 - accuracy: 0.5145\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.4982\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5203\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5246\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5103\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5119\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5029\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5320\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5198\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5325\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5272\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5362\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5309\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5230\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5277\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5420\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5161\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5177\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5431\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5298\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5309\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5383\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5330\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5283\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5394\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5362\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5341\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5330\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5346\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5489\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5499\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5372\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5325\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5272\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5346\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5320\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5526\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5325\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5515\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5225\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5494\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5478\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5431\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5320\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5478\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5510\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5478\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.5547\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5489\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5510\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5499\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5277\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5446\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5425\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5494\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5526\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5452\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5452\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5441\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5547\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5557\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5510\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5557\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16b3eb0a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16b3eb0a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  28%|████████▎                      | 12/43 [01:43<04:50]  28%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.43089640919659006\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5218289847584604\n",
      "X and y train shapes: \n",
      "(2009, 20)\n",
      "(2009,)\n",
      "Train set - Class 0 (Low Stress): 966, Class 1 (High Stress): 1043\n",
      "Test set - Class 0 (Low Stress): 12, Class 1 (High Stress): 0\n",
      "Test set size: 12\n",
      "Train set shape: (2009, 20)\n",
      "Test set shape: (12, 20)\n",
      "(2009, 20)\n",
      "(12, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.039855072463768, 1: 0.9630872483221476}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.4988\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5027\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4918\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5197\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5197\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5142\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5212\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5256\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5167\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5207\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5182\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5231\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5162\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5207\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5212\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5077\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5027\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5037\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5047\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5057\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4993\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5072\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5062\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5142\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5057\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5032\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5027\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.4988\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5037\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5142\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5062\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5137\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5231\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5157\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5107\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5137\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5162\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5286\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5082\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5127\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5092\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5246\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5122\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5251\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5137\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5172\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5182\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5212\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5182\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5336\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5281\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5331\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5217\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5226\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5316\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5296\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5341\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5341\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 799us/step - loss: 0.6886 - accuracy: 0.5217\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.6868 - accuracy: 0.5301\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.6856 - accuracy: 0.5326\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 472us/step - loss: 0.6836 - accuracy: 0.5455\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 457us/step - loss: 0.6833 - accuracy: 0.5316\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6807 - accuracy: 0.5416\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6841 - accuracy: 0.5455\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 440us/step - loss: 0.6863 - accuracy: 0.5386\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 440us/step - loss: 0.6830 - accuracy: 0.5286\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 443us/step - loss: 0.6853 - accuracy: 0.5421\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 447us/step - loss: 0.6812 - accuracy: 0.5455\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 439us/step - loss: 0.6834 - accuracy: 0.5490\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6829 - accuracy: 0.5371\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 448us/step - loss: 0.6803 - accuracy: 0.5495\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 493us/step - loss: 0.6804 - accuracy: 0.5326\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 462us/step - loss: 0.6824 - accuracy: 0.5406\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 469us/step - loss: 0.6796 - accuracy: 0.5585\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.6825 - accuracy: 0.5376\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 496us/step - loss: 0.6779 - accuracy: 0.5550\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 611us/step - loss: 0.6812 - accuracy: 0.5485\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 493us/step - loss: 0.6769 - accuracy: 0.5535\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 511us/step - loss: 0.6804 - accuracy: 0.5505\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 462us/step - loss: 0.6747 - accuracy: 0.5450\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 465us/step - loss: 0.6808 - accuracy: 0.5426\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 957us/step - loss: 0.6791 - accuracy: 0.5510\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5441\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5550\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5346\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5580\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.5585\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5207\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5475\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5401\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5455\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5505\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5525\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5500\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5530\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5575\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5346\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5406\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "LOSO CV Progress:  30%|█████████                      | 13/43 [01:54<04:54]  30%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AUC computation for this fold as y_test contains only one class: [0]\n",
      "Balanced Accuracy: 1.0\n",
      "X and y train shapes: \n",
      "(2005, 20)\n",
      "(2005,)\n",
      "Train set - Class 0 (Low Stress): 972, Class 1 (High Stress): 1033\n",
      "Test set - Class 0 (Low Stress): 6, Class 1 (High Stress): 10\n",
      "Test set size: 16\n",
      "Train set shape: (2005, 20)\n",
      "Test set shape: (16, 20)\n",
      "(2005, 20)\n",
      "(16, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0313786008230452, 1: 0.9704743465634076}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5127\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5027\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5067\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5042\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4938\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4898\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5162\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4993\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5007\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.4938\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5112\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5207\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 966us/step - loss: 0.6922 - accuracy: 0.5192\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.6919 - accuracy: 0.5167\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 565us/step - loss: 0.6931 - accuracy: 0.5092\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 480us/step - loss: 0.6904 - accuracy: 0.5212\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 440us/step - loss: 0.6904 - accuracy: 0.5167\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6914 - accuracy: 0.5057\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6915 - accuracy: 0.5147\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6898 - accuracy: 0.5197\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6909 - accuracy: 0.5262\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 414us/step - loss: 0.6911 - accuracy: 0.5067\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 438us/step - loss: 0.6898 - accuracy: 0.5102\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 461us/step - loss: 0.6886 - accuracy: 0.5222\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 441us/step - loss: 0.6911 - accuracy: 0.5117\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6903 - accuracy: 0.5202\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.6919 - accuracy: 0.5097\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 479us/step - loss: 0.6882 - accuracy: 0.5157\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.6900 - accuracy: 0.5132\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 439us/step - loss: 0.6904 - accuracy: 0.5227\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6898 - accuracy: 0.5277\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6877 - accuracy: 0.5317\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 447us/step - loss: 0.6893 - accuracy: 0.5262\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 454us/step - loss: 0.6882 - accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 440us/step - loss: 0.6883 - accuracy: 0.5262\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 439us/step - loss: 0.6898 - accuracy: 0.5062\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 451us/step - loss: 0.6864 - accuracy: 0.5322\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6894 - accuracy: 0.5212\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6883 - accuracy: 0.5077\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6871 - accuracy: 0.5297\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 440us/step - loss: 0.6880 - accuracy: 0.5297\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 453us/step - loss: 0.6869 - accuracy: 0.5287\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 443us/step - loss: 0.6882 - accuracy: 0.5217\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 627us/step - loss: 0.6862 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5372\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5217\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5102\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5287\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5297\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5287\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5097\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5222\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5267\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5411\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5267\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5332\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5232\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5352\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5242\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5227\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5327\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5347\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5177\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5332\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5232\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5342\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5382\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5167\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5232\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5416\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5441\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5446\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5342\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5392\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5207\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5222\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5571\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5337\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5377\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5431\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5337\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5217\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5382\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5421\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5322\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5431\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5431\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5352\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5317\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5317\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5332\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5421\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5357\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5491\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5471\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5377\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5416\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5411\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5456\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  33%|█████████▊                     | 14/43 [02:01<04:17]  33%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6666666666666666\n",
      "Balanced Accuracy: 0.6\n",
      "X and y train shapes: \n",
      "(1895, 20)\n",
      "(1895,)\n",
      "Train set - Class 0 (Low Stress): 948, Class 1 (High Stress): 947\n",
      "Test set - Class 0 (Low Stress): 30, Class 1 (High Stress): 96\n",
      "Test set size: 126\n",
      "Train set shape: (1895, 20)\n",
      "Test set shape: (126, 20)\n",
      "(1895, 20)\n",
      "(126, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 0.9994725738396625, 1: 1.0005279831045406}\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.4908\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4918\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5055\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5087\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5124\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5103\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5098\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5082\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5182\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5219\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5282\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5172\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5245\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5182\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5198\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5303\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5224\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5187\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5261\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5230\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5335\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5203\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 775us/step - loss: 0.6883 - accuracy: 0.5356\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 798us/step - loss: 0.6912 - accuracy: 0.5277\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.6902 - accuracy: 0.5224\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 457us/step - loss: 0.6904 - accuracy: 0.5251\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 449us/step - loss: 0.6899 - accuracy: 0.5256\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 447us/step - loss: 0.6908 - accuracy: 0.5282\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 446us/step - loss: 0.6907 - accuracy: 0.5325\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 439us/step - loss: 0.6897 - accuracy: 0.5198\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 434us/step - loss: 0.6908 - accuracy: 0.5235\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 453us/step - loss: 0.6898 - accuracy: 0.5219\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 436us/step - loss: 0.6912 - accuracy: 0.5166\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 430us/step - loss: 0.6893 - accuracy: 0.5282\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 432us/step - loss: 0.6885 - accuracy: 0.5293\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 433us/step - loss: 0.6881 - accuracy: 0.5293\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 437us/step - loss: 0.6884 - accuracy: 0.5266\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 435us/step - loss: 0.6881 - accuracy: 0.5393\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 425us/step - loss: 0.6882 - accuracy: 0.5351\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 430us/step - loss: 0.6892 - accuracy: 0.5235\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 428us/step - loss: 0.6879 - accuracy: 0.5298\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 436us/step - loss: 0.6857 - accuracy: 0.5430\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 427us/step - loss: 0.6880 - accuracy: 0.5346\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 429us/step - loss: 0.6888 - accuracy: 0.5251\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 437us/step - loss: 0.6874 - accuracy: 0.5340\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 434us/step - loss: 0.6878 - accuracy: 0.5414\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 435us/step - loss: 0.6870 - accuracy: 0.5319\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 430us/step - loss: 0.6886 - accuracy: 0.5219\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 431us/step - loss: 0.6887 - accuracy: 0.5303\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 433us/step - loss: 0.6890 - accuracy: 0.5235\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 440us/step - loss: 0.6899 - accuracy: 0.5298\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 430us/step - loss: 0.6893 - accuracy: 0.5325\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 431us/step - loss: 0.6869 - accuracy: 0.5335\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.6870 - accuracy: 0.5277\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5383\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5330\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5325\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5383\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5383\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5282\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5398\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5361\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5330\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5367\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5541\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5488\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5456\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5298\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5351\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5414\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5356\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5462\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5425\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5467\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5446\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5536\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5414\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5404\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5351\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5493\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5425\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5425\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5541\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5472\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5467\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5398\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5388\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5583\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5551\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5488\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5573\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5620\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5520\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5551\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5551\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5520\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5367\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5430\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5472\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  35%|██████████▍                    | 15/43 [02:07<03:46]  35%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5111111111111111\n",
      "Balanced Accuracy: 0.5458333333333334\n",
      "X and y train shapes: \n",
      "(2017, 20)\n",
      "(2017,)\n",
      "Train set - Class 0 (Low Stress): 976, Class 1 (High Stress): 1041\n",
      "Test set - Class 0 (Low Stress): 2, Class 1 (High Stress): 2\n",
      "Test set size: 4\n",
      "Train set shape: (2017, 20)\n",
      "Test set shape: (4, 20)\n",
      "(2017, 20)\n",
      "(4, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0332991803278688, 1: 0.9687800192122958}\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.4983\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4888\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4839\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4893\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4839\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4859\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4809\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4888\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5141\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4854\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4819\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4854\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4839\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4918\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5012\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5161\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5151\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5012\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5221\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5176\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5206\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5136\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5226\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5211\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5206\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5186\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5131\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4943\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4963\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5047\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5191\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5186\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4983\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5240\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.4903\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.4998\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4933\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.4948\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 913us/step - loss: 0.6934 - accuracy: 0.4888\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 860us/step - loss: 0.6920 - accuracy: 0.4913\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 711us/step - loss: 0.6890 - accuracy: 0.4993\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 451us/step - loss: 0.6902 - accuracy: 0.5062\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 445us/step - loss: 0.6909 - accuracy: 0.5022\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 430us/step - loss: 0.6917 - accuracy: 0.4998\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 434us/step - loss: 0.6900 - accuracy: 0.4913\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 428us/step - loss: 0.6897 - accuracy: 0.4968\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 422us/step - loss: 0.6921 - accuracy: 0.4948\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 431us/step - loss: 0.6917 - accuracy: 0.5047\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 438us/step - loss: 0.6917 - accuracy: 0.4938\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 440us/step - loss: 0.6908 - accuracy: 0.4958\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 434us/step - loss: 0.6918 - accuracy: 0.4943\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 404us/step - loss: 0.6895 - accuracy: 0.5017\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 428us/step - loss: 0.6910 - accuracy: 0.4943\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 424us/step - loss: 0.6911 - accuracy: 0.4874\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 426us/step - loss: 0.6878 - accuracy: 0.5082\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 428us/step - loss: 0.6918 - accuracy: 0.4978\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 432us/step - loss: 0.6899 - accuracy: 0.5002\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 439us/step - loss: 0.6906 - accuracy: 0.4948\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5027\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.4993\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.4973\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5032\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5002\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5027\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.4953\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.4968\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.4913\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5240\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5047\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5017\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5002\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.4918\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.4948\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.4998\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.4988\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.4963\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5052\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5012\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5037\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5027\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.4978\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5052\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.4983\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5017\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5057\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5002\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5102\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.4998\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5017\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5062\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5047\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5121\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5126\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.4988\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.4968\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5017\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5107\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5012\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5255\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  37%|███████████▏                   | 16/43 [02:14<03:30]  37%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.75\n",
      "Balanced Accuracy: 0.75\n",
      "X and y train shapes: \n",
      "(1973, 20)\n",
      "(1973,)\n",
      "Train set - Class 0 (Low Stress): 935, Class 1 (High Stress): 1038\n",
      "Test set - Class 0 (Low Stress): 43, Class 1 (High Stress): 5\n",
      "Test set size: 48\n",
      "Train set shape: (1973, 20)\n",
      "Test set shape: (48, 20)\n",
      "(1973, 20)\n",
      "(48, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0550802139037434, 1: 0.9503853564547207}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5043\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5084\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5322\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5378\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5079\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5210\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5210\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5160\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5291\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5210\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5373\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5226\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5094\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5327\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5433\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5438\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5373\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5307\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5454\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5271\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5271\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5352\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5443\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5423\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5443\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5337\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5373\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5509\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5352\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5423\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5479\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5489\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5428\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5423\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5621\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5499\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5464\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5550\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 0.6885 - accuracy: 0.5408\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 690us/step - loss: 0.6886 - accuracy: 0.5307\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 638us/step - loss: 0.6889 - accuracy: 0.5474\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 643us/step - loss: 0.6881 - accuracy: 0.5514\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 461us/step - loss: 0.6884 - accuracy: 0.5555\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.6876 - accuracy: 0.5408\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6867 - accuracy: 0.5575\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.6888 - accuracy: 0.5514\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.6879 - accuracy: 0.5459\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.6866 - accuracy: 0.5509\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.6847 - accuracy: 0.5565\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6857 - accuracy: 0.5666\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.6871 - accuracy: 0.5464\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.6848 - accuracy: 0.5575\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.6861 - accuracy: 0.5560\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6895 - accuracy: 0.5474\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.6857 - accuracy: 0.5585\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6830 - accuracy: 0.5677\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6864 - accuracy: 0.5535\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6851 - accuracy: 0.5611\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.6873 - accuracy: 0.5489\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.6844 - accuracy: 0.5580\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6822 - accuracy: 0.5616\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6846 - accuracy: 0.5585\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.6864 - accuracy: 0.5596\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5666\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5504\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5590\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5590\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5768\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5717\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5661\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5626\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5545\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5697\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5692\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5824\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5555\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5682\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5520\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5661\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5651\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5621\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5656\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5677\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5687\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5727\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5768\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5732\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5717\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5697\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5656\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5707\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5656\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5839\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.5813\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5601\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5732\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5829\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5621\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  40%|███████████▊                   | 17/43 [02:21<03:14]  40%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.2302325581395349\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(2000, 20)\n",
      "(2000,)\n",
      "Train set - Class 0 (Low Stress): 961, Class 1 (High Stress): 1039\n",
      "Test set - Class 0 (Low Stress): 17, Class 1 (High Stress): 4\n",
      "Test set size: 21\n",
      "Train set shape: (2000, 20)\n",
      "Test set shape: (21, 20)\n",
      "(2000, 20)\n",
      "(21, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0405827263267429, 1: 0.9624639076034649}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.5090\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5180\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5110\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5220\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5110\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5005\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5270\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5165\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5335\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5170\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5215\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5155\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5225\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5130\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5375\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5275\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5165\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5150\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5330\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5310\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5180\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5300\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5340\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5150\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5410\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5185\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5205\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5225\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5270\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5370\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5325\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5140\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5130\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5160\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5240\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5270\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5350\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5255\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5290\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5225\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5305\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5270\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5320\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5385\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5380\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 920us/step - loss: 0.6908 - accuracy: 0.5410\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 657us/step - loss: 0.6899 - accuracy: 0.5360\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 464us/step - loss: 0.6908 - accuracy: 0.5340\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6895 - accuracy: 0.5290\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 443us/step - loss: 0.6891 - accuracy: 0.5350\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6899 - accuracy: 0.5205\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6890 - accuracy: 0.5525\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6887 - accuracy: 0.5225\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6890 - accuracy: 0.5415\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 829us/step - loss: 0.6874 - accuracy: 0.5240\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 450us/step - loss: 0.6896 - accuracy: 0.5375\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 441us/step - loss: 0.6867 - accuracy: 0.5285\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6889 - accuracy: 0.5360\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 439us/step - loss: 0.6856 - accuracy: 0.5330\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6914 - accuracy: 0.5185\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6881 - accuracy: 0.5400\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6876 - accuracy: 0.5345\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6854 - accuracy: 0.5290\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6899 - accuracy: 0.5295\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6859 - accuracy: 0.5405\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.6880 - accuracy: 0.5355\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5495\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5490\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5395\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5380\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5430\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5610\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5415\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5465\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5455\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5460\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5285\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5505\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5390\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5495\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5515\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5570\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5430\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5340\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5520\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5480\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5445\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5420\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5425\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5380\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5410\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5445\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5565\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5350\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5500\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5515\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5505\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5420\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5690\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5415\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  42%|████████████▌                  | 18/43 [02:28<03:06]  42%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.22794117647058826\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(1987, 20)\n",
      "(1987,)\n",
      "Train set - Class 0 (Low Stress): 971, Class 1 (High Stress): 1016\n",
      "Test set - Class 0 (Low Stress): 7, Class 1 (High Stress): 27\n",
      "Test set size: 34\n",
      "Train set shape: (1987, 20)\n",
      "Test set shape: (34, 20)\n",
      "(1987, 20)\n",
      "(34, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0231719876416066, 1: 0.9778543307086615}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.4977\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.4992\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4967\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4877\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4912\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5028\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4841\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5053\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5058\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4992\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4942\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5053\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5058\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.4957\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5028\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4972\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5038\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4897\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5003\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5108\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5184\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5224\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5229\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5229\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5189\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5033\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5078\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5164\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5148\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5118\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5088\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5143\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5194\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5179\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5063\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5118\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5023\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5113\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5244\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5274\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5153\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5430\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5214\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5294\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.6903 - accuracy: 0.5259\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 463us/step - loss: 0.6877 - accuracy: 0.5450\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 443us/step - loss: 0.6893 - accuracy: 0.5209\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 442us/step - loss: 0.6900 - accuracy: 0.5028\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6888 - accuracy: 0.5315\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6873 - accuracy: 0.5249\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6891 - accuracy: 0.5274\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6871 - accuracy: 0.5315\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 440us/step - loss: 0.6885 - accuracy: 0.5148\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 445us/step - loss: 0.6869 - accuracy: 0.5415\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6861 - accuracy: 0.5274\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6882 - accuracy: 0.5234\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6893 - accuracy: 0.5254\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 595us/step - loss: 0.6871 - accuracy: 0.5299\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 443us/step - loss: 0.6891 - accuracy: 0.5481\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6846 - accuracy: 0.5370\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6872 - accuracy: 0.5209\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6878 - accuracy: 0.5405\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6873 - accuracy: 0.5420\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 895us/step - loss: 0.6865 - accuracy: 0.5234\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5264\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5355\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5315\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5466\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5370\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5340\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5294\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5199\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5440\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5284\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5516\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5506\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5476\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5466\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5471\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5420\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5476\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5450\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5506\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5571\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5390\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5365\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5365\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5611\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5571\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5491\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5476\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5501\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5466\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5511\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5360\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5506\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5460\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5531\n",
      "2/2 [==============================] - 0s 862us/step\n",
      "2/2 [==============================] - 0s 870us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  44%|█████████████▎                 | 19/43 [02:39<03:22]  44%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.42857142857142855\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5185185185185185\n",
      "X and y train shapes: \n",
      "(1991, 20)\n",
      "(1991,)\n",
      "Train set - Class 0 (Low Stress): 958, Class 1 (High Stress): 1033\n",
      "Test set - Class 0 (Low Stress): 20, Class 1 (High Stress): 10\n",
      "Test set size: 30\n",
      "Train set shape: (1991, 20)\n",
      "Test set shape: (30, 20)\n",
      "(1991, 20)\n",
      "(30, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.039144050104384, 1: 0.9636979670861568}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 506us/step - loss: 0.7014 - accuracy: 0.4902\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6946 - accuracy: 0.4852\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6950 - accuracy: 0.4792\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6950 - accuracy: 0.4937\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6935 - accuracy: 0.4912\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6945 - accuracy: 0.4776\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 436us/step - loss: 0.6924 - accuracy: 0.4877\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 564us/step - loss: 0.6936 - accuracy: 0.4932\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5103\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4972\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4882\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5083\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4947\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5173\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4927\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4927\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5043\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.4937\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4982\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5088\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4967\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4957\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5028\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5218\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5038\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5048\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5068\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5053\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5103\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5229\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5008\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5103\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5008\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5103\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 713us/step - loss: 0.6908 - accuracy: 0.5133\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6898 - accuracy: 0.5234\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 522us/step - loss: 0.6906 - accuracy: 0.5108\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 624us/step - loss: 0.6901 - accuracy: 0.5128\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 580us/step - loss: 0.6911 - accuracy: 0.5218\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.6905 - accuracy: 0.5118\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 528us/step - loss: 0.6909 - accuracy: 0.5158\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.6896 - accuracy: 0.5103\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.6889 - accuracy: 0.5148\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 491us/step - loss: 0.6893 - accuracy: 0.5289\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 496us/step - loss: 0.6910 - accuracy: 0.5118\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 501us/step - loss: 0.6905 - accuracy: 0.5103\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.6890 - accuracy: 0.5173\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 551us/step - loss: 0.6878 - accuracy: 0.5203\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.6887 - accuracy: 0.5329\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 521us/step - loss: 0.6879 - accuracy: 0.5384\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.6886 - accuracy: 0.5269\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.6887 - accuracy: 0.5188\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 585us/step - loss: 0.6877 - accuracy: 0.5239\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 553us/step - loss: 0.6870 - accuracy: 0.5249\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.6878 - accuracy: 0.5198\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.6864 - accuracy: 0.5213\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 670us/step - loss: 0.6878 - accuracy: 0.5244\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 522us/step - loss: 0.6883 - accuracy: 0.5344\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 593us/step - loss: 0.6880 - accuracy: 0.5259\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.6902 - accuracy: 0.5213\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.6882 - accuracy: 0.5244\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 488us/step - loss: 0.6874 - accuracy: 0.5173\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 495us/step - loss: 0.6878 - accuracy: 0.5234\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 507us/step - loss: 0.6871 - accuracy: 0.5183\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 656us/step - loss: 0.6866 - accuracy: 0.5284\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 629us/step - loss: 0.6884 - accuracy: 0.5183\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 580us/step - loss: 0.6847 - accuracy: 0.5384\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 592us/step - loss: 0.6878 - accuracy: 0.5314\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 806us/step - loss: 0.6897 - accuracy: 0.5173\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 577us/step - loss: 0.6860 - accuracy: 0.5414\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 773us/step - loss: 0.6845 - accuracy: 0.5314\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 891us/step - loss: 0.6846 - accuracy: 0.5439\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 603us/step - loss: 0.6882 - accuracy: 0.5304\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 565us/step - loss: 0.6896 - accuracy: 0.5198\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 625us/step - loss: 0.6835 - accuracy: 0.5269\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 638us/step - loss: 0.6889 - accuracy: 0.5208\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.6846 - accuracy: 0.5354\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.6838 - accuracy: 0.5419\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 459us/step - loss: 0.6880 - accuracy: 0.5198\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 468us/step - loss: 0.6845 - accuracy: 0.5309\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6823 - accuracy: 0.5470\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 436us/step - loss: 0.6848 - accuracy: 0.5409\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6888 - accuracy: 0.5254\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6872 - accuracy: 0.5173\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 455us/step - loss: 0.6830 - accuracy: 0.5374\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5419\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5279\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5294\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5379\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5309\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5334\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5359\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5269\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5419\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5399\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5505\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5399\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5324\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5485\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  47%|█████████████▉                 | 20/43 [02:45<02:56]  47%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7\n",
      "Balanced Accuracy: 0.65\n",
      "X and y train shapes: \n",
      "(1989, 20)\n",
      "(1989,)\n",
      "Train set - Class 0 (Low Stress): 972, Class 1 (High Stress): 1017\n",
      "Test set - Class 0 (Low Stress): 6, Class 1 (High Stress): 26\n",
      "Test set size: 32\n",
      "Train set shape: (1989, 20)\n",
      "Test set shape: (32, 20)\n",
      "(1989, 20)\n",
      "(32, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0231481481481481, 1: 0.9778761061946902}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.4972\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5138\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5098\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5133\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5123\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5209\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5173\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5178\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5204\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5148\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5244\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5204\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5103\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5189\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5194\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5219\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5219\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5254\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5153\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5214\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 739us/step - loss: 0.6935 - accuracy: 0.5153\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 504us/step - loss: 0.6919 - accuracy: 0.5264\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 486us/step - loss: 0.6936 - accuracy: 0.5148\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6927 - accuracy: 0.5178\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6919 - accuracy: 0.5173\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6912 - accuracy: 0.5349\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6917 - accuracy: 0.5365\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6924 - accuracy: 0.5209\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6927 - accuracy: 0.5294\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6926 - accuracy: 0.5199\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6923 - accuracy: 0.5324\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6913 - accuracy: 0.5289\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6931 - accuracy: 0.5168\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6911 - accuracy: 0.5289\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6884 - accuracy: 0.5470\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6926 - accuracy: 0.5400\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6920 - accuracy: 0.5314\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6926 - accuracy: 0.5178\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6905 - accuracy: 0.5354\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6910 - accuracy: 0.5299\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6907 - accuracy: 0.5365\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5349\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5410\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5289\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5309\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5410\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5370\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5264\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5490\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5344\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5380\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5415\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5314\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5455\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5359\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5420\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5349\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5385\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5480\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5390\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5440\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5344\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5485\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5430\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5410\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5495\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5375\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5465\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5510\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5445\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5440\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5495\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5480\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5505\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5571\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5470\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5561\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5440\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5400\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5551\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5470\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5440\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5646\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5505\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5571\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5455\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5495\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5420\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5591\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5510\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5591\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5636\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5490\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5535\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5505\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5495\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5631\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5546\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5520\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5530\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  49%|██████████████▋                | 21/43 [02:52<02:46]  49%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.40384615384615385\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5256410256410257\n",
      "X and y train shapes: \n",
      "(1986, 20)\n",
      "(1986,)\n",
      "Train set - Class 0 (Low Stress): 973, Class 1 (High Stress): 1013\n",
      "Test set - Class 0 (Low Stress): 5, Class 1 (High Stress): 30\n",
      "Test set size: 35\n",
      "Train set shape: (1986, 20)\n",
      "Test set shape: (35, 20)\n",
      "(1986, 20)\n",
      "(35, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0205549845837616, 1: 0.9802566633761106}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.4879\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5050\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5111\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5146\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5186\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5262\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5136\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5121\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5262\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5146\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5106\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5050\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5337\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5217\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5272\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5317\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5076\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5171\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 910us/step - loss: 0.6902 - accuracy: 0.5337\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 498us/step - loss: 0.6912 - accuracy: 0.5206\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 450us/step - loss: 0.6923 - accuracy: 0.5222\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6925 - accuracy: 0.5222\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6923 - accuracy: 0.5352\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6939 - accuracy: 0.5181\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 459us/step - loss: 0.6891 - accuracy: 0.5383\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 463us/step - loss: 0.6918 - accuracy: 0.5181\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 459us/step - loss: 0.6916 - accuracy: 0.5211\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 480us/step - loss: 0.6924 - accuracy: 0.5156\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6876 - accuracy: 0.5388\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6928 - accuracy: 0.5307\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6888 - accuracy: 0.5347\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6909 - accuracy: 0.5388\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6915 - accuracy: 0.5358\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6903 - accuracy: 0.5413\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 438us/step - loss: 0.6914 - accuracy: 0.5247\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5473\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5453\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5126\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5358\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5327\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5448\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5373\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5252\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5398\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5564\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5383\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5327\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5418\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5514\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5493\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5463\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5423\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5277\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5493\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5277\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5317\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5211\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5393\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5504\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5488\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5498\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5388\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5433\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5539\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5342\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5574\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5428\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5519\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5524\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5488\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5408\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5473\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5463\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5504\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5589\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5569\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5443\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5514\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5599\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5468\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5629\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5514\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5418\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5363\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5373\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5483\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5468\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5504\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5549\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5448\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5554\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5690\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5519\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5443\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5619\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5559\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5408\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5710\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5473\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "AUC Score: 0.59"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  51%|███████████████▎               | 22/43 [03:00<02:38]  51%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Accuracy: 0.6666666666666667\n",
      "X and y train shapes: \n",
      "(1999, 20)\n",
      "(1999,)\n",
      "Train set - Class 0 (Low Stress): 960, Class 1 (High Stress): 1039\n",
      "Test set - Class 0 (Low Stress): 18, Class 1 (High Stress): 4\n",
      "Test set size: 22\n",
      "Train set shape: (1999, 20)\n",
      "Test set shape: (22, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 20)\n",
      "(22, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0411458333333334, 1: 0.9619826756496631}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.4957\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.4942\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5083\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5233\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5138\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5103\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5183\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5148\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5158\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 867us/step - loss: 0.6931 - accuracy: 0.5113\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 672us/step - loss: 0.6919 - accuracy: 0.5428\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 579us/step - loss: 0.6936 - accuracy: 0.5163\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.6933 - accuracy: 0.5158\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6937 - accuracy: 0.5148\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6936 - accuracy: 0.5133\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6923 - accuracy: 0.5253\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 436us/step - loss: 0.6926 - accuracy: 0.5243\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6920 - accuracy: 0.5358\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6911 - accuracy: 0.5243\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6928 - accuracy: 0.5293\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6917 - accuracy: 0.5368\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6915 - accuracy: 0.5388\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6937 - accuracy: 0.5178\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6920 - accuracy: 0.5338\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6921 - accuracy: 0.5188\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6916 - accuracy: 0.5338\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6911 - accuracy: 0.5483\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6922 - accuracy: 0.5273\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6921 - accuracy: 0.5278\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6928 - accuracy: 0.5233\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 448us/step - loss: 0.6921 - accuracy: 0.5263\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 457us/step - loss: 0.6912 - accuracy: 0.5358\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 447us/step - loss: 0.6904 - accuracy: 0.5408\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 441us/step - loss: 0.6922 - accuracy: 0.5298\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6895 - accuracy: 0.5418\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6913 - accuracy: 0.5303\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6919 - accuracy: 0.5338\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6903 - accuracy: 0.5468\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6896 - accuracy: 0.5313\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5343\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5483\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5348\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5363\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5413\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5353\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5303\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5263\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5353\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5428\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5313\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5523\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5463\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5388\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5413\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5368\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5273\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5503\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5408\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5428\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5548\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5518\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5423\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5403\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5358\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5623\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5508\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5458\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5478\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5473\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5573\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5668\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5503\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5388\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5693\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5648\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5453\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5478\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5593\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5573\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5618\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5438\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5688\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5568\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5583\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5608\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5708\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5483\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5698\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5503\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5628\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5553\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5618\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5638\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5603\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5588\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5578\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5553\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5528\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  53%|████████████████               | 23/43 [03:10<02:50]  53%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.611111111111111\n",
      "Balanced Accuracy: 0.6527777777777778\n",
      "X and y train shapes: \n",
      "(1974, 20)\n",
      "(1974,)\n",
      "Train set - Class 0 (Low Stress): 931, Class 1 (High Stress): 1043\n",
      "Test set - Class 0 (Low Stress): 47, Class 1 (High Stress): 0\n",
      "Test set size: 47\n",
      "Train set shape: (1974, 20)\n",
      "Test set shape: (47, 20)\n",
      "(1974, 20)\n",
      "(47, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0601503759398496, 1: 0.9463087248322147}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 598us/step - loss: 0.7034 - accuracy: 0.4848\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6951 - accuracy: 0.4863\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6946 - accuracy: 0.5086\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.6933 - accuracy: 0.5203\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.6926 - accuracy: 0.5223\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 415us/step - loss: 0.6939 - accuracy: 0.5208\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.6942 - accuracy: 0.5304\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 451us/step - loss: 0.6929 - accuracy: 0.5193\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 406us/step - loss: 0.6926 - accuracy: 0.5324\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 407us/step - loss: 0.6924 - accuracy: 0.5299\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 406us/step - loss: 0.6934 - accuracy: 0.5233\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.6928 - accuracy: 0.5274\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 413us/step - loss: 0.6937 - accuracy: 0.5127\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6934 - accuracy: 0.5213\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 395us/step - loss: 0.6925 - accuracy: 0.5294\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 398us/step - loss: 0.6936 - accuracy: 0.5248\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 501us/step - loss: 0.6940 - accuracy: 0.5299\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.6923 - accuracy: 0.5324\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6922 - accuracy: 0.5253\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 464us/step - loss: 0.6943 - accuracy: 0.5314\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 401us/step - loss: 0.6919 - accuracy: 0.5218\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.6930 - accuracy: 0.5294\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 456us/step - loss: 0.6930 - accuracy: 0.5208\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6927 - accuracy: 0.5289\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 496us/step - loss: 0.6918 - accuracy: 0.5355\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 475us/step - loss: 0.6912 - accuracy: 0.5390\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.6916 - accuracy: 0.5329\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6913 - accuracy: 0.5390\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 468us/step - loss: 0.6926 - accuracy: 0.5350\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 402us/step - loss: 0.6896 - accuracy: 0.5360\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6921 - accuracy: 0.5390\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6922 - accuracy: 0.5375\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 453us/step - loss: 0.6921 - accuracy: 0.5350\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.6899 - accuracy: 0.5410\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 484us/step - loss: 0.6918 - accuracy: 0.5319\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 456us/step - loss: 0.6921 - accuracy: 0.5309\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 459us/step - loss: 0.6929 - accuracy: 0.5329\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 480us/step - loss: 0.6918 - accuracy: 0.5319\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.6891 - accuracy: 0.5360\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 489us/step - loss: 0.6913 - accuracy: 0.5319\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.6887 - accuracy: 0.5405\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 498us/step - loss: 0.6907 - accuracy: 0.5329\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.6905 - accuracy: 0.5436\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 654us/step - loss: 0.6904 - accuracy: 0.5385\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 564us/step - loss: 0.6906 - accuracy: 0.5390\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 568us/step - loss: 0.6873 - accuracy: 0.5527\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 570us/step - loss: 0.6881 - accuracy: 0.5456\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 529us/step - loss: 0.6896 - accuracy: 0.5562\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 558us/step - loss: 0.6888 - accuracy: 0.5375\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 538us/step - loss: 0.6880 - accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 529us/step - loss: 0.6910 - accuracy: 0.5289\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 485us/step - loss: 0.6921 - accuracy: 0.5370\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 556us/step - loss: 0.6887 - accuracy: 0.5517\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 578us/step - loss: 0.6877 - accuracy: 0.5426\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 617us/step - loss: 0.6894 - accuracy: 0.5461\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 602us/step - loss: 0.6885 - accuracy: 0.5466\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 538us/step - loss: 0.6862 - accuracy: 0.5431\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 542us/step - loss: 0.6891 - accuracy: 0.5309\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 514us/step - loss: 0.6893 - accuracy: 0.5517\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 519us/step - loss: 0.6901 - accuracy: 0.5410\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 486us/step - loss: 0.6899 - accuracy: 0.5213\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 564us/step - loss: 0.6877 - accuracy: 0.5496\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 542us/step - loss: 0.6869 - accuracy: 0.5431\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 554us/step - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 502us/step - loss: 0.6861 - accuracy: 0.5507\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 551us/step - loss: 0.6892 - accuracy: 0.5410\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 514us/step - loss: 0.6864 - accuracy: 0.5522\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 532us/step - loss: 0.6867 - accuracy: 0.5375\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 508us/step - loss: 0.6857 - accuracy: 0.5491\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 508us/step - loss: 0.6839 - accuracy: 0.5557\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 558us/step - loss: 0.6863 - accuracy: 0.5491\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 521us/step - loss: 0.6831 - accuracy: 0.5502\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 484us/step - loss: 0.6841 - accuracy: 0.5562\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 536us/step - loss: 0.6885 - accuracy: 0.5481\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 554us/step - loss: 0.6837 - accuracy: 0.5496\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 496us/step - loss: 0.6852 - accuracy: 0.5481\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 548us/step - loss: 0.6859 - accuracy: 0.5431\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 542us/step - loss: 0.6847 - accuracy: 0.5618\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 588us/step - loss: 0.6839 - accuracy: 0.5491\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 570us/step - loss: 0.6847 - accuracy: 0.5567\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 587us/step - loss: 0.6845 - accuracy: 0.5583\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 593us/step - loss: 0.6846 - accuracy: 0.5618\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 485us/step - loss: 0.6874 - accuracy: 0.5426\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 463us/step - loss: 0.6836 - accuracy: 0.5547\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5491\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5481\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5633\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5532\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5704\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5405\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5572\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5557\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5481\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5557\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5618\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5532\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5659\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5527\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5750\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "LOSO CV Progress:  56%|████████████████▋              | 24/43 [03:15<02:18]  56%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AUC computation for this fold as y_test contains only one class: [0]\n",
      "Balanced Accuracy: 1.0\n",
      "X and y train shapes: \n",
      "(1934, 20)\n",
      "(1934,)\n",
      "Train set - Class 0 (Low Stress): 940, Class 1 (High Stress): 994\n",
      "Test set - Class 0 (Low Stress): 38, Class 1 (High Stress): 49\n",
      "Test set size: 87\n",
      "Train set shape: (1934, 20)\n",
      "Test set shape: (87, 20)\n",
      "(1934, 20)\n",
      "(87, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.028723404255319, 1: 0.9728370221327968}\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.5171\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4912\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5098\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.4845\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4881\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 876us/step - loss: 0.6932 - accuracy: 0.4824\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 657us/step - loss: 0.6924 - accuracy: 0.4860\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 651us/step - loss: 0.6932 - accuracy: 0.4809\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 463us/step - loss: 0.6927 - accuracy: 0.4948\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 424us/step - loss: 0.6926 - accuracy: 0.4953\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6914 - accuracy: 0.4907\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6926 - accuracy: 0.4902\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 422us/step - loss: 0.6910 - accuracy: 0.4886\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6939 - accuracy: 0.4979\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6911 - accuracy: 0.5274\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6924 - accuracy: 0.4933\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6917 - accuracy: 0.5196\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 424us/step - loss: 0.6935 - accuracy: 0.4959\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 423us/step - loss: 0.6920 - accuracy: 0.5134\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 424us/step - loss: 0.6908 - accuracy: 0.5248\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6908 - accuracy: 0.5217\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6923 - accuracy: 0.5191\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6938 - accuracy: 0.5119\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6897 - accuracy: 0.4959\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 428us/step - loss: 0.6915 - accuracy: 0.5243\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 428us/step - loss: 0.6907 - accuracy: 0.5248\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 450us/step - loss: 0.6892 - accuracy: 0.5140\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5171\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5310\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5124\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5279\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5109\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5196\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5243\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5279\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5321\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5305\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5336\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5165\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5274\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5109\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5196\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5357\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5186\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5217\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5383\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5295\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5372\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5393\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5155\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5460\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5465\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5403\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5326\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5372\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5196\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5222\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5140\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5434\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5274\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5445\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5321\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5248\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5486\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5424\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5326\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5408\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5445\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5548\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5486\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5429\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5641\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5476\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5507\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5305\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5383\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5455\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5476\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5471\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5455\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5414\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5383\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5367\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5491\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5429\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5589\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5522\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5605\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5507\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5357\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.5589\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5321\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.5605\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5424\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5502\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5533\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5305\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5476\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.5584\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5558\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  58%|█████████████████▍             | 25/43 [03:22<02:10]  58%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5698174006444683\n",
      "Balanced Accuracy: 0.569280343716434\n",
      "X and y train shapes: \n",
      "(2016, 20)\n",
      "(2016,)\n",
      "Train set - Class 0 (Low Stress): 973, Class 1 (High Stress): 1043\n",
      "Test set - Class 0 (Low Stress): 5, Class 1 (High Stress): 0\n",
      "Test set size: 5\n",
      "Train set shape: (2016, 20)\n",
      "Test set shape: (5, 20)\n",
      "(2016, 20)\n",
      "(5, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0359712230215827, 1: 0.9664429530201343}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5074\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 979us/step - loss: 0.6936 - accuracy: 0.5159\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5164\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5174\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5149\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5203\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.6942 - accuracy: 0.5139\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.6930 - accuracy: 0.5169\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.6935 - accuracy: 0.5149\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 498us/step - loss: 0.6928 - accuracy: 0.5243\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6933 - accuracy: 0.5164\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 404us/step - loss: 0.6933 - accuracy: 0.5198\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 398us/step - loss: 0.6928 - accuracy: 0.5198\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 397us/step - loss: 0.6932 - accuracy: 0.5114\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 399us/step - loss: 0.6931 - accuracy: 0.5159\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6928 - accuracy: 0.5208\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 451us/step - loss: 0.6934 - accuracy: 0.5149\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6927 - accuracy: 0.5208\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6934 - accuracy: 0.5169\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6930 - accuracy: 0.5184\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 405us/step - loss: 0.6923 - accuracy: 0.4990\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6933 - accuracy: 0.5213\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 405us/step - loss: 0.6916 - accuracy: 0.5298\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 406us/step - loss: 0.6909 - accuracy: 0.5243\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6930 - accuracy: 0.5223\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6927 - accuracy: 0.5218\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6914 - accuracy: 0.5278\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5218\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5198\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 999us/step - loss: 0.6928 - accuracy: 0.5193\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5248\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5278\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5228\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5208\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5367\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5184\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5253\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5288\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5198\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5283\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5159\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5218\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5288\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5347\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5223\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5218\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5248\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5164\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5278\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5268\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5228\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5342\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5248\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5347\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5288\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5169\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5303\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5223\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5208\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5303\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5293\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5203\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5268\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5238\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5208\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5283\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5327\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5273\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5283\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5238\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5223\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5248\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5179\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5218\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5278\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5193\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5258\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5179\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5352\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5258\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5298\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5332\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5283\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5357\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5218\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5303\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5139\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5293\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5288\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5342\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5288\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5402\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5243\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5367\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5248\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5342\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5461\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5228\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5327\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/models_run/lib/python3.10/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "LOSO CV Progress:  60%|██████████████████▏            | 26/43 [03:29<02:01]  60%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AUC computation for this fold as y_test contains only one class: [0]\n",
      "Balanced Accuracy: 1.0\n",
      "X and y train shapes: \n",
      "(1989, 20)\n",
      "(1989,)\n",
      "Train set - Class 0 (Low Stress): 957, Class 1 (High Stress): 1032\n",
      "Test set - Class 0 (Low Stress): 21, Class 1 (High Stress): 11\n",
      "Test set size: 32\n",
      "Train set shape: (1989, 20)\n",
      "Test set shape: (32, 20)\n",
      "(1989, 20)\n",
      "(32, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0391849529780564, 1: 0.9636627906976745}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.4922\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.4862\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4852\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4862\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4847\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5028\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4977\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5123\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5143\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5178\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5123\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 847us/step - loss: 0.6920 - accuracy: 0.4937\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.6925 - accuracy: 0.4967\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 484us/step - loss: 0.6925 - accuracy: 0.4972\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 447us/step - loss: 0.6908 - accuracy: 0.5168\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6913 - accuracy: 0.4877\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 414us/step - loss: 0.6924 - accuracy: 0.4997\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6921 - accuracy: 0.4887\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6929 - accuracy: 0.5113\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6920 - accuracy: 0.4992\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6883 - accuracy: 0.5314\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6924 - accuracy: 0.5068\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6934 - accuracy: 0.4987\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6922 - accuracy: 0.5194\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6926 - accuracy: 0.5309\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6903 - accuracy: 0.5184\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6946 - accuracy: 0.5033\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6892 - accuracy: 0.5380\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6889 - accuracy: 0.5163\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6907 - accuracy: 0.5269\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6914 - accuracy: 0.5264\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6913 - accuracy: 0.5204\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6906 - accuracy: 0.5264\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6895 - accuracy: 0.5294\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 445us/step - loss: 0.6913 - accuracy: 0.5173\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5329\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5189\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5289\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5163\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5465\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5365\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5324\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5359\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5390\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5334\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5510\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5189\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5264\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5500\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5329\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5349\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5395\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5339\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5556\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5420\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5370\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5375\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5395\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5460\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5500\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5430\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5415\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5525\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5490\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5400\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5430\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5425\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5420\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5500\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5299\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5334\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5400\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5495\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5440\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5515\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5475\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5505\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5500\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5385\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5626\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5385\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5495\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5626\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5505\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5576\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5601\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5510\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5656\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5520\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5475\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5591\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5530\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5566\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5500\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5576\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5485\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5525\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5455\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5581\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5571\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  63%|██████████████████▊            | 27/43 [03:40<02:12]  63%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5757575757575758\n",
      "Balanced Accuracy: 0.5974025974025974\n",
      "X and y train shapes: \n",
      "(1983, 20)\n",
      "(1983,)\n",
      "Train set - Class 0 (Low Stress): 972, Class 1 (High Stress): 1011\n",
      "Test set - Class 0 (Low Stress): 6, Class 1 (High Stress): 32\n",
      "Test set size: 38\n",
      "Train set shape: (1983, 20)\n",
      "Test set shape: (38, 20)\n",
      "(1983, 20)\n",
      "(38, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0200617283950617, 1: 0.9807121661721068}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5018\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5164\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5078\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5093\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5169\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5038\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5219\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5169\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5154\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5154\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5164\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5134\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5194\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5330\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5144\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5088\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5199\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5179\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5265\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5204\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5134\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5164\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5164\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5189\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5219\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5078\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5159\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5194\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5204\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5209\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5189\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5340\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5209\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5169\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5189\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5209\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5305\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5411\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5295\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5285\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5255\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5224\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5219\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5255\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5421\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5154\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5305\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5330\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5295\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 994us/step - loss: 0.6860 - accuracy: 0.5219\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 595us/step - loss: 0.6894 - accuracy: 0.5345\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 477us/step - loss: 0.6859 - accuracy: 0.5381\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.6867 - accuracy: 0.5315\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6876 - accuracy: 0.5219\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.6885 - accuracy: 0.5300\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.6880 - accuracy: 0.5320\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6840 - accuracy: 0.5366\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6832 - accuracy: 0.5527\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6872 - accuracy: 0.5330\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6841 - accuracy: 0.5386\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 443us/step - loss: 0.6805 - accuracy: 0.5497\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.6876 - accuracy: 0.5310\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6839 - accuracy: 0.5361\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.6876 - accuracy: 0.5250\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.6854 - accuracy: 0.5335\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6855 - accuracy: 0.5310\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6837 - accuracy: 0.5416\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6849 - accuracy: 0.5446\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.6851 - accuracy: 0.5401\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5436\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5320\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5381\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5421\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5436\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5451\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5371\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5532\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5335\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5345\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5270\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5335\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5562\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5512\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5492\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5512\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5416\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5340\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5547\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5371\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5502\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5406\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5345\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5492\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5552\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5386\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5582\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5376\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5678\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5724\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5532\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  65%|███████████████████▌           | 28/43 [03:48<02:01]  65%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.3385416666666667\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5104166666666667\n",
      "X and y train shapes: \n",
      "(2009, 20)\n",
      "(2009,)\n",
      "Train set - Class 0 (Low Stress): 973, Class 1 (High Stress): 1036\n",
      "Test set - Class 0 (Low Stress): 5, Class 1 (High Stress): 7\n",
      "Test set size: 12\n",
      "Train set shape: (2009, 20)\n",
      "Test set shape: (12, 20)\n",
      "(2009, 20)\n",
      "(12, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weight:  {0: 1.0323741007194245, 1: 0.9695945945945946}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.4983\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5112\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5062\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5107\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5147\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5157\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5266\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5172\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5202\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5102\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5062\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5142\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5162\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5187\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5142\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5212\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5157\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5142\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5202\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5122\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5207\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5182\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5212\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5197\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5222\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4878\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5207\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5172\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5157\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5217\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5127\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5182\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5092\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5127\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4888\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.4938\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.4788\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5052\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5152\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5017\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5241\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5122\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 678us/step - loss: 0.6916 - accuracy: 0.4848\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 641us/step - loss: 0.6866 - accuracy: 0.5301\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 456us/step - loss: 0.6936 - accuracy: 0.4943\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6914 - accuracy: 0.5286\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6886 - accuracy: 0.5281\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 405us/step - loss: 0.6924 - accuracy: 0.5241\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 409us/step - loss: 0.6887 - accuracy: 0.4928\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6912 - accuracy: 0.5012\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6899 - accuracy: 0.4943\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6847 - accuracy: 0.5002\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6857 - accuracy: 0.4998\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6901 - accuracy: 0.5027\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6892 - accuracy: 0.4878\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6876 - accuracy: 0.4963\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6883 - accuracy: 0.5072\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6885 - accuracy: 0.5246\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6880 - accuracy: 0.5032\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6864 - accuracy: 0.5217\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6873 - accuracy: 0.5331\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6880 - accuracy: 0.5306\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6877 - accuracy: 0.4993\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.4928\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5246\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5261\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5027\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5321\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5366\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5366\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5256\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5386\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5301\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5371\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5336\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5316\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5261\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5450\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5361\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5306\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5291\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5226\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5356\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5391\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5381\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5386\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5341\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5441\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5391\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5520\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5177\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5316\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5381\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5520\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5396\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5341\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5361\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5351\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5301\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5416\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  67%|████████████████████▏          | 29/43 [03:58<02:04]  67%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.4285714285714285\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5714285714285714\n",
      "X and y train shapes: \n",
      "(1992, 20)\n",
      "(1992,)\n",
      "Train set - Class 0 (Low Stress): 967, Class 1 (High Stress): 1025\n",
      "Test set - Class 0 (Low Stress): 11, Class 1 (High Stress): 18\n",
      "Test set size: 29\n",
      "Train set shape: (1992, 20)\n",
      "Test set shape: (29, 20)\n",
      "(1992, 20)\n",
      "(29, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0299896587383661, 1: 0.9717073170731707}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.7117 - accuracy: 0.5010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 910us/step - loss: 0.6964 - accuracy: 0.4915\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5030\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5075\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4940\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5055\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.5010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5055\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5110\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4874\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5126\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4960\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5090\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5191\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4890\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5065\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5131\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5211\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5191\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5095\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5191\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5181\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5186\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5095\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5321\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5211\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5065\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5156\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5161\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5070\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5221\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5216\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5311\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5341\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5286\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5105\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5151\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5171\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5331\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5251\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5110\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5341\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5281\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5286\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5231\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5176\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5402\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5246\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5221\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5271\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5171\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5291\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5517\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5221\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5226\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5261\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5366\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5346\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5166\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5382\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5407\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5311\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5432\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5306\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5417\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5356\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5462\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5442\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5366\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5276\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5311\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5301\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5487\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5407\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5412\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5432\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5361\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5331\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5422\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5371\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5392\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5467\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5366\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5402\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5522\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5427\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5346\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5517\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 911us/step - loss: 0.6832 - accuracy: 0.5392\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.6802 - accuracy: 0.5467\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 441us/step - loss: 0.6774 - accuracy: 0.5482\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6787 - accuracy: 0.5387\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6809 - accuracy: 0.5377\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6778 - accuracy: 0.5552\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6793 - accuracy: 0.5597\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6828 - accuracy: 0.5492\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6797 - accuracy: 0.5477\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 446us/step - loss: 0.6805 - accuracy: 0.5492\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  70%|████████████████████▉          | 30/43 [04:06<01:49]  70%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.4090909090909091\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5833333333333334\n",
      "X and y train shapes: \n",
      "(1967, 20)\n",
      "(1967,)\n",
      "Train set - Class 0 (Low Stress): 946, Class 1 (High Stress): 1021\n",
      "Test set - Class 0 (Low Stress): 32, Class 1 (High Stress): 22\n",
      "Test set size: 54\n",
      "Train set shape: (1967, 20)\n",
      "Test set shape: (54, 20)\n",
      "(1967, 20)\n",
      "(54, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0396405919661733, 1: 0.9632713026444663}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.4997\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5170\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5191\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5175\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5358\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5053\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5119\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5048\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4987\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5145\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5191\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5191\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5302\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5211\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5226\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5287\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5130\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5262\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5216\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5180\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5236\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5247\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5211\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5216\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5186\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5348\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5328\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5125\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5328\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5267\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5201\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5287\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5206\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5282\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5231\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5241\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5318\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5435\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5348\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5338\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5292\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5170\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5374\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5353\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5358\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5343\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5536\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5353\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5277\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5531\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5425\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5465\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5389\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5369\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5313\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5313\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5394\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5430\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5541\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5419\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5292\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5287\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5425\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5460\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5445\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5338\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5475\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5404\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5328\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5521\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5430\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5602\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5557\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5496\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5511\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5597\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5552\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5475\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5577\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.6788 - accuracy: 0.5628\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 654us/step - loss: 0.6791 - accuracy: 0.5648\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 663us/step - loss: 0.6776 - accuracy: 0.5592\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 585us/step - loss: 0.6786 - accuracy: 0.5567\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.6819 - accuracy: 0.5689\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.6807 - accuracy: 0.5516\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6773 - accuracy: 0.5643\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 403us/step - loss: 0.6792 - accuracy: 0.5780\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6797 - accuracy: 0.5521\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.6821 - accuracy: 0.5521\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 429us/step - loss: 0.6775 - accuracy: 0.5597\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6809 - accuracy: 0.5608\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6799 - accuracy: 0.5577\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6769 - accuracy: 0.5679\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 416us/step - loss: 0.6781 - accuracy: 0.5719\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6806 - accuracy: 0.5597\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 463us/step - loss: 0.6792 - accuracy: 0.5552\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 469us/step - loss: 0.6815 - accuracy: 0.5475\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 493us/step - loss: 0.6790 - accuracy: 0.5582\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 825us/step - loss: 0.6801 - accuracy: 0.5501\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5669\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  72%|█████████████████████▋         | 31/43 [04:13<01:35]  72%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.4822443181818182\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5667613636363636\n",
      "X and y train shapes: \n",
      "(1967, 20)\n",
      "(1967,)\n",
      "Train set - Class 0 (Low Stress): 952, Class 1 (High Stress): 1015\n",
      "Test set - Class 0 (Low Stress): 26, Class 1 (High Stress): 28\n",
      "Test set size: 54\n",
      "Train set shape: (1967, 20)\n",
      "Test set shape: (54, 20)\n",
      "(1967, 20)\n",
      "(54, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0330882352941178, 1: 0.9689655172413794}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7090 - accuracy: 0.4972\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5018\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.4794\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5043\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5170\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5013\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5018\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4830\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4911\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4992\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5033\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.4997\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4972\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5028\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4942\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5094\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5028\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5125\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4992\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5099\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5130\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5206\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5028\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5074\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5231\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.4977\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5053\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5079\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5135\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5104\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5099\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.4992\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5089\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5079\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5008\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5038\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5175\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.4992\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5130\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5140\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5099\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5165\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5155\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5033\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.4952\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5048\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5033\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5008\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5109\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5140\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5175\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5069\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5150\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5135\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5109\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5180\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5135\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5084\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5119\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5069\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5130\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5170\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5165\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5211\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5094\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5180\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5247\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5140\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5104\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5221\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5170\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5130\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5155\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5130\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5125\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5165\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5206\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5084\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5089\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 839us/step - loss: 0.6849 - accuracy: 0.5140\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 756us/step - loss: 0.6877 - accuracy: 0.5196\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.6883 - accuracy: 0.5114\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.6838 - accuracy: 0.5231\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.6880 - accuracy: 0.5033\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.6875 - accuracy: 0.5058\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6868 - accuracy: 0.5140\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6881 - accuracy: 0.5038\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6863 - accuracy: 0.5079\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.6847 - accuracy: 0.5191\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.6864 - accuracy: 0.5114\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.6852 - accuracy: 0.5140\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6858 - accuracy: 0.5104\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6854 - accuracy: 0.5104\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.6857 - accuracy: 0.5160\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.6862 - accuracy: 0.5160\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 426us/step - loss: 0.6849 - accuracy: 0.5165\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 425us/step - loss: 0.6871 - accuracy: 0.5048\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6873 - accuracy: 0.5165\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 711us/step - loss: 0.6868 - accuracy: 0.5196\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  74%|██████████████████████▎        | 32/43 [04:20<01:24]  74%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.40659340659340654\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(1961, 20)\n",
      "(1961,)\n",
      "Train set - Class 0 (Low Stress): 945, Class 1 (High Stress): 1016\n",
      "Test set - Class 0 (Low Stress): 33, Class 1 (High Stress): 27\n",
      "Test set size: 60\n",
      "Train set shape: (1961, 20)\n",
      "Test set shape: (60, 20)\n",
      "(1961, 20)\n",
      "(60, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0375661375661376, 1: 0.9650590551181102}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 1ms/step - loss: 0.7151 - accuracy: 0.5023\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5110\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5171\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5156\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5232\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5207\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5288\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5140\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5171\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5089\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5150\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5110\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5110\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5237\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5288\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5120\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5344\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5120\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5258\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5207\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5212\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5288\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5120\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5166\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5314\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5191\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5176\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5344\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5319\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5303\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5288\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5416\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5135\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5411\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5319\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5237\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5196\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5329\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5268\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5314\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5380\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5196\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5431\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5405\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5400\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5451\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5354\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5288\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5385\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5461\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5288\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5365\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5441\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5365\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5385\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5303\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5380\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5354\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5431\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5477\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5467\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5237\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5365\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5390\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5599\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5416\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5614\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5507\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5492\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5405\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5502\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5502\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 956us/step - loss: 0.6809 - accuracy: 0.5472\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 635us/step - loss: 0.6879 - accuracy: 0.5390\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 494us/step - loss: 0.6818 - accuracy: 0.5563\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.6826 - accuracy: 0.5309\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 424us/step - loss: 0.6831 - accuracy: 0.5497\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6813 - accuracy: 0.5492\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 405us/step - loss: 0.6843 - accuracy: 0.5370\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 419us/step - loss: 0.6830 - accuracy: 0.5518\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.6861 - accuracy: 0.5523\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6806 - accuracy: 0.5589\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.6814 - accuracy: 0.5543\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.6862 - accuracy: 0.5512\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.6832 - accuracy: 0.5405\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.6856 - accuracy: 0.5446\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 420us/step - loss: 0.6821 - accuracy: 0.5553\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 422us/step - loss: 0.6829 - accuracy: 0.5436\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6801 - accuracy: 0.5472\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6835 - accuracy: 0.5548\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6793 - accuracy: 0.5461\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.6822 - accuracy: 0.5548\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 715us/step - loss: 0.6789 - accuracy: 0.5569\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5609\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5569\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5563\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5523\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5477\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5553\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  77%|███████████████████████        | 33/43 [04:27<01:16]  77%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5347923681257014\n",
      "Balanced Accuracy: 0.5471380471380471\n",
      "X and y train shapes: \n",
      "(2010, 20)\n",
      "(2010,)\n",
      "Train set - Class 0 (Low Stress): 972, Class 1 (High Stress): 1038\n",
      "Test set - Class 0 (Low Stress): 6, Class 1 (High Stress): 5\n",
      "Test set size: 11\n",
      "Train set shape: (2010, 20)\n",
      "Test set shape: (11, 20)\n",
      "(2010, 20)\n",
      "(11, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0339506172839505, 1: 0.9682080924855492}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.5090\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.4905\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4925\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4990\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5020\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4980\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4925\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4871\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4886\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4925\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4960\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5025\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4940\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4935\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4985\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5025\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4905\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5095\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4876\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4851\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4950\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4900\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5010\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5030\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5050\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.4990\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5025\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5035\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5040\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4965\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4886\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4896\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4950\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4925\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5035\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5149\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5209\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5075\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5085\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4960\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5154\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5065\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5030\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5129\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5149\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5104\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5254\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5219\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5070\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5313\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5279\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5104\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5224\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5104\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5070\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5264\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5279\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5498\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5338\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5338\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5259\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5378\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5259\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5284\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5294\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5353\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5289\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 809us/step - loss: 0.6870 - accuracy: 0.5259\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 653us/step - loss: 0.6847 - accuracy: 0.5289\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 641us/step - loss: 0.6865 - accuracy: 0.5303\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 502us/step - loss: 0.6877 - accuracy: 0.5299\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 439us/step - loss: 0.6886 - accuracy: 0.5328\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6860 - accuracy: 0.5318\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6831 - accuracy: 0.5438\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6877 - accuracy: 0.5318\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6861 - accuracy: 0.5209\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6888 - accuracy: 0.5179\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6885 - accuracy: 0.5294\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6842 - accuracy: 0.5368\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6850 - accuracy: 0.5259\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6880 - accuracy: 0.5328\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6860 - accuracy: 0.5114\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6855 - accuracy: 0.5254\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 441us/step - loss: 0.6833 - accuracy: 0.5358\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6870 - accuracy: 0.5269\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6832 - accuracy: 0.5408\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6843 - accuracy: 0.5353\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6833 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6858 - accuracy: 0.5249\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6823 - accuracy: 0.5363\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6832 - accuracy: 0.5328\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6830 - accuracy: 0.5353\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6815 - accuracy: 0.5398\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6844 - accuracy: 0.5224\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6837 - accuracy: 0.5353\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6819 - accuracy: 0.5348\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 448us/step - loss: 0.6824 - accuracy: 0.5279\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 438us/step - loss: 0.6820 - accuracy: 0.5303\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 450us/step - loss: 0.6817 - accuracy: 0.5383\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  79%|███████████████████████▋       | 34/43 [04:34<01:07]  79%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.65\n",
      "Balanced Accuracy: 0.7\n",
      "X and y train shapes: \n",
      "(1910, 20)\n",
      "(1910,)\n",
      "Train set - Class 0 (Low Stress): 938, Class 1 (High Stress): 972\n",
      "Test set - Class 0 (Low Stress): 40, Class 1 (High Stress): 71\n",
      "Test set size: 111\n",
      "Train set shape: (1910, 20)\n",
      "Test set shape: (111, 20)\n",
      "(1910, 20)\n",
      "(111, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0181236673773988, 1: 0.9825102880658436}\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.5021\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4984\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4942\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5031\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4885\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4880\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5026\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.4832\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4953\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.4958\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4995\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4979\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.4874\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4942\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5010\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4874\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4974\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4953\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4921\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4953\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4937\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4942\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4890\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4948\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4916\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4895\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4927\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4937\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4932\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4969\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5099\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4869\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.4864\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4932\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4775\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4832\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4942\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4958\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4864\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4785\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5047\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5063\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4963\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4916\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5105\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5251\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5131\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5110\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4796\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4895\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5147\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5052\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5079\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5147\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5152\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5068\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5152\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5209\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5168\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5393\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5309\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5215\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5408\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5309\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5277\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5251\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5267\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5262\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5277\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5262\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5435\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5429\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5173\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5325\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5356\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5429\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5408\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5340\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5450\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 798us/step - loss: 0.6893 - accuracy: 0.5435\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 884us/step - loss: 0.6883 - accuracy: 0.5503\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 746us/step - loss: 0.6905 - accuracy: 0.5267\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 455us/step - loss: 0.6888 - accuracy: 0.5293\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 431us/step - loss: 0.6877 - accuracy: 0.5440\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 422us/step - loss: 0.6882 - accuracy: 0.5356\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 421us/step - loss: 0.6896 - accuracy: 0.5340\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 430us/step - loss: 0.6868 - accuracy: 0.5414\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 421us/step - loss: 0.6856 - accuracy: 0.5450\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 440us/step - loss: 0.6885 - accuracy: 0.5429\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 436us/step - loss: 0.6890 - accuracy: 0.5319\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 434us/step - loss: 0.6885 - accuracy: 0.5440\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 436us/step - loss: 0.6861 - accuracy: 0.5445\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 426us/step - loss: 0.6889 - accuracy: 0.5377\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 424us/step - loss: 0.6860 - accuracy: 0.5445\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 423us/step - loss: 0.6854 - accuracy: 0.5586\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 427us/step - loss: 0.6870 - accuracy: 0.5251\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 426us/step - loss: 0.6895 - accuracy: 0.5356\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 425us/step - loss: 0.6884 - accuracy: 0.5429\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 428us/step - loss: 0.6858 - accuracy: 0.5492\n",
      "4/4 [==============================] - 0s 428us/step\n",
      "4/4 [==============================] - 0s 437us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  81%|████████████████████████▍      | 35/43 [04:41<00:59]  81%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.4095070422535211\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5070422535211268\n",
      "X and y train shapes: \n",
      "(1984, 20)\n",
      "(1984,)\n",
      "Train set - Class 0 (Low Stress): 975, Class 1 (High Stress): 1009\n",
      "Test set - Class 0 (Low Stress): 3, Class 1 (High Stress): 34\n",
      "Test set size: 37\n",
      "Train set shape: (1984, 20)\n",
      "Test set shape: (37, 20)\n",
      "(1984, 20)\n",
      "(37, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0174358974358975, 1: 0.9831516352824579}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 499us/step - loss: 0.7115 - accuracy: 0.4874\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 580us/step - loss: 0.6957 - accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5015\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5025\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5131\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5091\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5055\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5101\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5121\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5076\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5136\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4940\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4808\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5086\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5101\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5101\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5302\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5055\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5212\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5086\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5186\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5146\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5086\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5071\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5136\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5121\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5116\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5151\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5272\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5146\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5060\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5161\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5227\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5126\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5166\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5212\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5156\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5126\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5262\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5207\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5126\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5050\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5166\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5015\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5227\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5232\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5242\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5091\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5222\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5207\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5126\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5282\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5166\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5307\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5166\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5222\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5252\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5146\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5045\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4884\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5076\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4909\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5121\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5030\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5146\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4934\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5055\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5171\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5202\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5060\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5202\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5015\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5091\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5030\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5176\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5146\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5131\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.4904\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.4904\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.4839\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5126\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5202\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.4924\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.4985\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5010\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 708us/step - loss: 0.6877 - accuracy: 0.5161\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 573us/step - loss: 0.6840 - accuracy: 0.5171\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 464us/step - loss: 0.6873 - accuracy: 0.5227\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6882 - accuracy: 0.5348\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.6876 - accuracy: 0.5403\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 452us/step - loss: 0.6915 - accuracy: 0.5212\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.6873 - accuracy: 0.5388\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6881 - accuracy: 0.5363\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6894 - accuracy: 0.5252\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 840us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  84%|█████████████████████████      | 36/43 [04:49<00:51]  84%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6911764705882353\n",
      "Balanced Accuracy: 0.6715686274509804\n",
      "X and y train shapes: \n",
      "(1953, 20)\n",
      "(1953,)\n",
      "Train set - Class 0 (Low Stress): 950, Class 1 (High Stress): 1003\n",
      "Test set - Class 0 (Low Stress): 28, Class 1 (High Stress): 40\n",
      "Test set size: 68\n",
      "Train set shape: (1953, 20)\n",
      "Test set shape: (68, 20)\n",
      "(1953, 20)\n",
      "(68, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0278947368421052, 1: 0.9735792622133599}\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 511us/step - loss: 0.7103 - accuracy: 0.5151\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.6956 - accuracy: 0.4941\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 432us/step - loss: 0.6932 - accuracy: 0.5187\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 423us/step - loss: 0.6937 - accuracy: 0.5049\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 417us/step - loss: 0.6925 - accuracy: 0.5212\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 485us/step - loss: 0.6934 - accuracy: 0.5110\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 980us/step - loss: 0.6928 - accuracy: 0.5253\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5105\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5177\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5233\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4962\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5177\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5187\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5294\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5166\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5141\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5166\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5202\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5182\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5187\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5120\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5269\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5187\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5218\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5054\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5151\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5346\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5192\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5315\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5284\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5284\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5259\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5300\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5253\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5361\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5320\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5172\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5223\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5341\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5289\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5341\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5264\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5284\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5212\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5417\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5064\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5289\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5294\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5325\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5346\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5223\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5269\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5202\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5192\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5284\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5320\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5248\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5269\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5202\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5315\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5335\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5330\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5197\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5248\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5412\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5233\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5320\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5305\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5453\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5463\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5407\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5289\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5335\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5356\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5346\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5417\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5438\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5346\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5407\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5474\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5397\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5504\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5376\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5346\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5422\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.6878 - accuracy: 0.5448\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 653us/step - loss: 0.6881 - accuracy: 0.5397\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 600us/step - loss: 0.6864 - accuracy: 0.5417\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.6843 - accuracy: 0.5499\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6893 - accuracy: 0.5387\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 421us/step - loss: 0.6862 - accuracy: 0.5489\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 408us/step - loss: 0.6895 - accuracy: 0.5366\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.6850 - accuracy: 0.5463\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 455us/step - loss: 0.6851 - accuracy: 0.5412\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.6876 - accuracy: 0.5320\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 428us/step - loss: 0.6833 - accuracy: 0.5479\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 427us/step - loss: 0.6874 - accuracy: 0.5438\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 412us/step - loss: 0.6861 - accuracy: 0.5525\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 412us/step - loss: 0.6883 - accuracy: 0.5422\n",
      "3/3 [==============================] - 0s 521us/step\n",
      "3/3 [==============================] - 0s 661us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  86%|█████████████████████████▊     | 37/43 [04:56<00:44]  86%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5433035714285714\n",
      "Balanced Accuracy: 0.5428571428571429\n",
      "X and y train shapes: \n",
      "(1990, 20)\n",
      "(1990,)\n",
      "Train set - Class 0 (Low Stress): 970, Class 1 (High Stress): 1020\n",
      "Test set - Class 0 (Low Stress): 8, Class 1 (High Stress): 23\n",
      "Test set size: 31\n",
      "Train set shape: (1990, 20)\n",
      "Test set shape: (31, 20)\n",
      "(1990, 20)\n",
      "(31, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0257731958762886, 1: 0.9754901960784313}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.4864\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4935\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5085\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5020\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5055\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5015\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.4995\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4950\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4940\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5025\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5121\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4940\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5045\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5065\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4945\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4925\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4935\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4854\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4980\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4930\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4950\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4894\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4945\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.4799\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4950\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.4985\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4945\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.4950\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.4975\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4965\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4920\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4930\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5281\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5035\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5236\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5121\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5191\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5362\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5146\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5317\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5106\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5291\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5231\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5196\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5291\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5186\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5392\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5256\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5412\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5271\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5156\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5276\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5347\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5302\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5191\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5342\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5487\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5337\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5357\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5302\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5322\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5407\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5347\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5487\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5422\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5342\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5407\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5407\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5452\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5427\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5407\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5332\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5332\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5417\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5447\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5553\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5422\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 886us/step - loss: 0.6872 - accuracy: 0.5332\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 502us/step - loss: 0.6873 - accuracy: 0.5327\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 581us/step - loss: 0.6869 - accuracy: 0.5261\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 544us/step - loss: 0.6855 - accuracy: 0.5497\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 515us/step - loss: 0.6853 - accuracy: 0.5467\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 500us/step - loss: 0.6860 - accuracy: 0.5286\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.6843 - accuracy: 0.5508\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.6807 - accuracy: 0.5648\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 453us/step - loss: 0.6830 - accuracy: 0.5598\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6829 - accuracy: 0.5523\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 443us/step - loss: 0.6840 - accuracy: 0.5437\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.6855 - accuracy: 0.5397\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6854 - accuracy: 0.5382\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6853 - accuracy: 0.5447\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6819 - accuracy: 0.5548\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6819 - accuracy: 0.5452\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5447\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5472\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5618\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5452\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5412\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5402\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  88%|██████████████████████████▌    | 38/43 [05:04<00:37]  88%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.2880434782608695\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5217391304347826\n",
      "X and y train shapes: \n",
      "(1991, 20)\n",
      "(1991,)\n",
      "Train set - Class 0 (Low Stress): 965, Class 1 (High Stress): 1026\n",
      "Test set - Class 0 (Low Stress): 13, Class 1 (High Stress): 17\n",
      "Test set size: 30\n",
      "Train set shape: (1991, 20)\n",
      "Test set shape: (30, 20)\n",
      "(1991, 20)\n",
      "(30, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0316062176165803, 1: 0.9702729044834308}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.4832\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.4817\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4867\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5038\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4842\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4907\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5103\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4957\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4942\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5028\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5013\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5043\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4977\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5033\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.4937\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.4927\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.4997\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4987\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.4992\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5093\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.4972\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5068\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5088\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4947\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4972\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5053\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5038\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5118\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5068\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5048\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5208\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5143\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.4927\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5093\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5068\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5168\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5113\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5083\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5048\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5078\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5133\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.4992\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5043\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.4972\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.4992\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5234\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5078\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5244\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5279\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5299\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5299\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5148\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5314\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5239\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5234\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5289\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5234\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5153\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 791us/step - loss: 0.6877 - accuracy: 0.5269\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 502us/step - loss: 0.6883 - accuracy: 0.5224\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 447us/step - loss: 0.6836 - accuracy: 0.5314\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 437us/step - loss: 0.6877 - accuracy: 0.5153\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6888 - accuracy: 0.5143\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6869 - accuracy: 0.5213\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6842 - accuracy: 0.5329\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6859 - accuracy: 0.5279\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 421us/step - loss: 0.6827 - accuracy: 0.5299\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 433us/step - loss: 0.6830 - accuracy: 0.5279\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 459us/step - loss: 0.6868 - accuracy: 0.5239\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6812 - accuracy: 0.5384\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 430us/step - loss: 0.6832 - accuracy: 0.5244\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6838 - accuracy: 0.5239\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.6848 - accuracy: 0.5229\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 438us/step - loss: 0.6812 - accuracy: 0.5349\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 445us/step - loss: 0.6863 - accuracy: 0.5234\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6850 - accuracy: 0.5314\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 435us/step - loss: 0.6849 - accuracy: 0.5379\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6825 - accuracy: 0.5299\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6806 - accuracy: 0.5213\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6844 - accuracy: 0.5379\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6873 - accuracy: 0.5304\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6844 - accuracy: 0.5244\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6842 - accuracy: 0.5419\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6842 - accuracy: 0.5414\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6819 - accuracy: 0.5339\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6809 - accuracy: 0.5374\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6820 - accuracy: 0.5364\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6784 - accuracy: 0.5429\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6803 - accuracy: 0.5460\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6796 - accuracy: 0.5535\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6803 - accuracy: 0.5329\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6777 - accuracy: 0.5409\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6751 - accuracy: 0.5540\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6775 - accuracy: 0.5450\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6785 - accuracy: 0.5409\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6806 - accuracy: 0.5364\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6799 - accuracy: 0.5515\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6793 - accuracy: 0.5535\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 425us/step - loss: 0.6817 - accuracy: 0.5525\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  91%|███████████████████████████▏   | 39/43 [05:11<00:28]  91%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6447963800904978\n",
      "Balanced Accuracy: 0.6312217194570136\n",
      "X and y train shapes: \n",
      "(1994, 20)\n",
      "(1994,)\n",
      "Train set - Class 0 (Low Stress): 969, Class 1 (High Stress): 1025\n",
      "Test set - Class 0 (Low Stress): 9, Class 1 (High Stress): 18\n",
      "Test set size: 27\n",
      "Train set shape: (1994, 20)\n",
      "Test set shape: (27, 20)\n",
      "(1994, 20)\n",
      "(27, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0288957688338494, 1: 0.9726829268292683}\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 455us/step - loss: 0.7117 - accuracy: 0.4895\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 409us/step - loss: 0.6939 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6917 - accuracy: 0.4950\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6942 - accuracy: 0.4900\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6924 - accuracy: 0.4955\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6939 - accuracy: 0.4960\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6938 - accuracy: 0.4840\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6932 - accuracy: 0.4895\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6930 - accuracy: 0.4865\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 414us/step - loss: 0.6934 - accuracy: 0.4900\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 414us/step - loss: 0.6924 - accuracy: 0.4930\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6918 - accuracy: 0.4940\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6927 - accuracy: 0.5065\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6932 - accuracy: 0.4970\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6930 - accuracy: 0.4895\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6927 - accuracy: 0.4875\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6926 - accuracy: 0.4950\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 406us/step - loss: 0.6927 - accuracy: 0.4935\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6929 - accuracy: 0.4990\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 407us/step - loss: 0.6917 - accuracy: 0.4970\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6946 - accuracy: 0.4965\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6914 - accuracy: 0.5040\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 409us/step - loss: 0.6897 - accuracy: 0.5030\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 409us/step - loss: 0.6900 - accuracy: 0.5155\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 405us/step - loss: 0.6943 - accuracy: 0.4940\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6897 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6917 - accuracy: 0.5005\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6917 - accuracy: 0.4990\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6921 - accuracy: 0.5070\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6938 - accuracy: 0.4970\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 395us/step - loss: 0.6913 - accuracy: 0.5020\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6920 - accuracy: 0.5035\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6915 - accuracy: 0.5045\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6889 - accuracy: 0.5090\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 415us/step - loss: 0.6920 - accuracy: 0.5065\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6912 - accuracy: 0.5045\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6907 - accuracy: 0.4985\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6916 - accuracy: 0.5020\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 408us/step - loss: 0.6900 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6914 - accuracy: 0.4975\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6885 - accuracy: 0.5070\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 414us/step - loss: 0.6885 - accuracy: 0.5040\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6924 - accuracy: 0.5105\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6901 - accuracy: 0.5095\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6876 - accuracy: 0.5206\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6901 - accuracy: 0.5105\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6890 - accuracy: 0.5176\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 408us/step - loss: 0.6894 - accuracy: 0.5165\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 411us/step - loss: 0.6852 - accuracy: 0.5261\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6894 - accuracy: 0.5105\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 408us/step - loss: 0.6863 - accuracy: 0.5211\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 408us/step - loss: 0.6870 - accuracy: 0.5065\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 406us/step - loss: 0.6901 - accuracy: 0.5095\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6898 - accuracy: 0.5070\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 406us/step - loss: 0.6899 - accuracy: 0.5085\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6880 - accuracy: 0.5155\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6883 - accuracy: 0.5060\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6895 - accuracy: 0.5020\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6876 - accuracy: 0.5191\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 414us/step - loss: 0.6880 - accuracy: 0.5211\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6894 - accuracy: 0.5155\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6889 - accuracy: 0.5110\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6896 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 424us/step - loss: 0.6886 - accuracy: 0.5251\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 436us/step - loss: 0.6881 - accuracy: 0.5171\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 409us/step - loss: 0.6880 - accuracy: 0.5261\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 423us/step - loss: 0.6851 - accuracy: 0.5336\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6846 - accuracy: 0.5276\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6833 - accuracy: 0.5130\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6848 - accuracy: 0.5246\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6886 - accuracy: 0.5236\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 419us/step - loss: 0.6859 - accuracy: 0.5251\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6857 - accuracy: 0.5191\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6874 - accuracy: 0.5246\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 407us/step - loss: 0.6874 - accuracy: 0.5221\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 591us/step - loss: 0.6884 - accuracy: 0.5160\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 431us/step - loss: 0.6855 - accuracy: 0.5246\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 441us/step - loss: 0.6889 - accuracy: 0.5191\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 429us/step - loss: 0.6829 - accuracy: 0.5336\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6881 - accuracy: 0.5181\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6855 - accuracy: 0.5201\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 416us/step - loss: 0.6886 - accuracy: 0.5125\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 404us/step - loss: 0.6882 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6865 - accuracy: 0.5206\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 408us/step - loss: 0.6852 - accuracy: 0.5196\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 454us/step - loss: 0.6861 - accuracy: 0.5306\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 434us/step - loss: 0.6864 - accuracy: 0.5221\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 446us/step - loss: 0.6855 - accuracy: 0.5196\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 466us/step - loss: 0.6842 - accuracy: 0.5246\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6828 - accuracy: 0.5221\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 432us/step - loss: 0.6875 - accuracy: 0.5286\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 426us/step - loss: 0.6820 - accuracy: 0.5306\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 422us/step - loss: 0.6831 - accuracy: 0.5291\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 417us/step - loss: 0.6808 - accuracy: 0.5321\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6823 - accuracy: 0.5261\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 420us/step - loss: 0.6819 - accuracy: 0.5236\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6869 - accuracy: 0.5165\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 418us/step - loss: 0.6827 - accuracy: 0.5226\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 410us/step - loss: 0.6835 - accuracy: 0.5271\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 548us/step - loss: 0.6836 - accuracy: 0.5261\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  93%|███████████████████████████▉   | 40/43 [05:14<00:17]  93%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7376543209876544\n",
      "Balanced Accuracy: 0.75\n",
      "X and y train shapes: \n",
      "(1937, 20)\n",
      "(1937,)\n",
      "Train set - Class 0 (Low Stress): 952, Class 1 (High Stress): 985\n",
      "Test set - Class 0 (Low Stress): 26, Class 1 (High Stress): 58\n",
      "Test set size: 84\n",
      "Train set shape: (1937, 20)\n",
      "Test set shape: (84, 20)\n",
      "(1937, 20)\n",
      "(84, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Defined\n",
      "Class Weight:  {0: 1.0173319327731092, 1: 0.983248730964467}\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 0s 461us/step - loss: 0.7067 - accuracy: 0.5132\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 408us/step - loss: 0.7010 - accuracy: 0.4879\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6927 - accuracy: 0.5018\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6926 - accuracy: 0.4972\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6934 - accuracy: 0.5003\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6918 - accuracy: 0.5023\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6919 - accuracy: 0.5013\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6937 - accuracy: 0.4987\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6939 - accuracy: 0.4977\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6928 - accuracy: 0.4920\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6941 - accuracy: 0.4925\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6930 - accuracy: 0.4982\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6934 - accuracy: 0.4946\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6938 - accuracy: 0.4915\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6933 - accuracy: 0.4966\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6923 - accuracy: 0.5008\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 407us/step - loss: 0.6926 - accuracy: 0.4972\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6915 - accuracy: 0.5003\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6932 - accuracy: 0.4966\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6926 - accuracy: 0.4977\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6938 - accuracy: 0.5096\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6919 - accuracy: 0.4977\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6926 - accuracy: 0.4956\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6925 - accuracy: 0.4925\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6933 - accuracy: 0.4935\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6926 - accuracy: 0.4951\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6913 - accuracy: 0.4956\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6916 - accuracy: 0.5018\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 406us/step - loss: 0.6916 - accuracy: 0.5101\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6918 - accuracy: 0.5049\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6912 - accuracy: 0.5008\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 406us/step - loss: 0.6895 - accuracy: 0.5090\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 763us/step - loss: 0.6924 - accuracy: 0.5070\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 425us/step - loss: 0.6915 - accuracy: 0.5028\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6906 - accuracy: 0.5059\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 422us/step - loss: 0.6927 - accuracy: 0.4956\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6901 - accuracy: 0.5059\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6945 - accuracy: 0.5039\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6926 - accuracy: 0.4972\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6926 - accuracy: 0.5013\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6905 - accuracy: 0.5137\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6904 - accuracy: 0.5023\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6890 - accuracy: 0.5292\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6905 - accuracy: 0.5173\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 407us/step - loss: 0.6909 - accuracy: 0.5034\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6904 - accuracy: 0.5142\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6898 - accuracy: 0.5111\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6911 - accuracy: 0.5090\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6877 - accuracy: 0.5178\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6903 - accuracy: 0.5204\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6890 - accuracy: 0.5194\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6892 - accuracy: 0.5157\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6910 - accuracy: 0.5168\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6875 - accuracy: 0.5214\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6887 - accuracy: 0.5096\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6886 - accuracy: 0.5152\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6903 - accuracy: 0.5152\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6882 - accuracy: 0.5183\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6882 - accuracy: 0.5219\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6909 - accuracy: 0.5194\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6874 - accuracy: 0.5121\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6889 - accuracy: 0.5163\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6873 - accuracy: 0.5287\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6872 - accuracy: 0.5276\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6883 - accuracy: 0.5199\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6886 - accuracy: 0.5204\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6884 - accuracy: 0.5204\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6912 - accuracy: 0.5147\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6886 - accuracy: 0.5235\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6859 - accuracy: 0.5230\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6853 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6862 - accuracy: 0.5297\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 408us/step - loss: 0.6840 - accuracy: 0.5173\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6865 - accuracy: 0.5194\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6861 - accuracy: 0.5385\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6827 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6866 - accuracy: 0.5364\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6882 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6884 - accuracy: 0.5245\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6876 - accuracy: 0.5235\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6854 - accuracy: 0.5271\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6866 - accuracy: 0.5297\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 410us/step - loss: 0.6835 - accuracy: 0.5364\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6865 - accuracy: 0.5271\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6852 - accuracy: 0.5276\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6836 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6831 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6848 - accuracy: 0.5364\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6823 - accuracy: 0.5436\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6827 - accuracy: 0.5256\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6837 - accuracy: 0.5235\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6835 - accuracy: 0.5338\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6815 - accuracy: 0.5338\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6831 - accuracy: 0.5235\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6810 - accuracy: 0.5410\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6832 - accuracy: 0.5354\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6835 - accuracy: 0.5318\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 406us/step - loss: 0.6848 - accuracy: 0.5271\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6839 - accuracy: 0.5256\n",
      "3/3 [==============================] - 0s 521us/step\n",
      "3/3 [==============================] - 0s 497us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  95%|████████████████████████████▌  | 41/43 [05:17<00:10]  95%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.541445623342175\n",
      "Balanced Accuracy: 0.5431034482758621\n",
      "X and y train shapes: \n",
      "(1939, 20)\n",
      "(1939,)\n",
      "Train set - Class 0 (Low Stress): 961, Class 1 (High Stress): 978\n",
      "Test set - Class 0 (Low Stress): 17, Class 1 (High Stress): 65\n",
      "Test set size: 82\n",
      "Train set shape: (1939, 20)\n",
      "Test set shape: (82, 20)\n",
      "(1939, 20)\n",
      "(82, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0088449531737773, 1: 0.9913087934560327}\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 0s 474us/step - loss: 0.7085 - accuracy: 0.5018\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6967 - accuracy: 0.4992\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6933 - accuracy: 0.4982\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6930 - accuracy: 0.4982\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6932 - accuracy: 0.5044\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6930 - accuracy: 0.5116\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6930 - accuracy: 0.4956\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6955 - accuracy: 0.4987\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6935 - accuracy: 0.4930\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6918 - accuracy: 0.5054\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6922 - accuracy: 0.4956\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6922 - accuracy: 0.5049\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6913 - accuracy: 0.5090\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 426us/step - loss: 0.6938 - accuracy: 0.5152\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6929 - accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6903 - accuracy: 0.5147\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6907 - accuracy: 0.5188\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6923 - accuracy: 0.5209\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6924 - accuracy: 0.5168\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6906 - accuracy: 0.5240\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6931 - accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6903 - accuracy: 0.5168\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6902 - accuracy: 0.5132\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6903 - accuracy: 0.5224\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6891 - accuracy: 0.5188\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6885 - accuracy: 0.5327\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6899 - accuracy: 0.5152\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6895 - accuracy: 0.5193\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6884 - accuracy: 0.5286\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6899 - accuracy: 0.5095\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6875 - accuracy: 0.5348\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6871 - accuracy: 0.5302\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6885 - accuracy: 0.5199\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6854 - accuracy: 0.5358\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6890 - accuracy: 0.5224\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6891 - accuracy: 0.5327\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6885 - accuracy: 0.5240\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6890 - accuracy: 0.5322\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 419us/step - loss: 0.6882 - accuracy: 0.5193\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6854 - accuracy: 0.5477\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6853 - accuracy: 0.5291\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6881 - accuracy: 0.5297\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6896 - accuracy: 0.5307\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6859 - accuracy: 0.5374\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6837 - accuracy: 0.5395\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6887 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6874 - accuracy: 0.5255\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 421us/step - loss: 0.6865 - accuracy: 0.5364\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6843 - accuracy: 0.5374\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6879 - accuracy: 0.5343\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6864 - accuracy: 0.5358\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 406us/step - loss: 0.6863 - accuracy: 0.5286\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6858 - accuracy: 0.5410\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 413us/step - loss: 0.6849 - accuracy: 0.5389\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 414us/step - loss: 0.6840 - accuracy: 0.5358\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6890 - accuracy: 0.5276\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 406us/step - loss: 0.6870 - accuracy: 0.5327\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6848 - accuracy: 0.5286\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6869 - accuracy: 0.5353\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6869 - accuracy: 0.5353\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6836 - accuracy: 0.5518\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 412us/step - loss: 0.6864 - accuracy: 0.5369\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 415us/step - loss: 0.6855 - accuracy: 0.5302\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6822 - accuracy: 0.5420\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6842 - accuracy: 0.5467\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6858 - accuracy: 0.5379\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 440us/step - loss: 0.6850 - accuracy: 0.5204\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 406us/step - loss: 0.6819 - accuracy: 0.5410\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6838 - accuracy: 0.5462\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6837 - accuracy: 0.5297\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 408us/step - loss: 0.6851 - accuracy: 0.5389\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 410us/step - loss: 0.6820 - accuracy: 0.5276\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6837 - accuracy: 0.5343\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 438us/step - loss: 0.6846 - accuracy: 0.5446\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6829 - accuracy: 0.5415\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6838 - accuracy: 0.5436\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 437us/step - loss: 0.6848 - accuracy: 0.5420\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6845 - accuracy: 0.5343\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 409us/step - loss: 0.6830 - accuracy: 0.5436\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 427us/step - loss: 0.6839 - accuracy: 0.5446\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 459us/step - loss: 0.6854 - accuracy: 0.5348\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 443us/step - loss: 0.6848 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 457us/step - loss: 0.6810 - accuracy: 0.5487\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 458us/step - loss: 0.6835 - accuracy: 0.5395\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 0s 420us/step - loss: 0.6830 - accuracy: 0.5554\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 429us/step - loss: 0.6796 - accuracy: 0.5560\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 431us/step - loss: 0.6780 - accuracy: 0.5544\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 438us/step - loss: 0.6829 - accuracy: 0.5379\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 425us/step - loss: 0.6790 - accuracy: 0.5523\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6863 - accuracy: 0.5374\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6798 - accuracy: 0.5508\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 443us/step - loss: 0.6818 - accuracy: 0.5456\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6833 - accuracy: 0.5405\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 416us/step - loss: 0.6792 - accuracy: 0.5565\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6785 - accuracy: 0.5549\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 444us/step - loss: 0.6791 - accuracy: 0.5725\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 418us/step - loss: 0.6788 - accuracy: 0.5462\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 422us/step - loss: 0.6818 - accuracy: 0.5498\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 411us/step - loss: 0.6814 - accuracy: 0.5462\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 417us/step - loss: 0.6737 - accuracy: 0.5611\n",
      "3/3 [==============================] - 0s 500us/step\n",
      "3/3 [==============================] - 0s 486us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  98%|█████████████████████████████▎ | 42/43 [05:19<00:04]  98%WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5429864253393665\n",
      "Balanced Accuracy: 0.5552036199095023\n",
      "X and y train shapes: \n",
      "(1869, 20)\n",
      "(1869,)\n",
      "Train set - Class 0 (Low Stress): 858, Class 1 (High Stress): 1011\n",
      "Test set - Class 0 (Low Stress): 120, Class 1 (High Stress): 32\n",
      "Test set size: 152\n",
      "Train set shape: (1869, 20)\n",
      "Test set shape: (152, 20)\n",
      "(1869, 20)\n",
      "(152, 20)\n",
      "Model Defined\n",
      "Class Weight:  {0: 1.0891608391608392, 1: 0.9243323442136498}\n",
      "Epoch 1/100\n",
      "59/59 [==============================] - 0s 431us/step - loss: 0.6998 - accuracy: 0.4880\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 0s 404us/step - loss: 0.6919 - accuracy: 0.5029\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 0s 419us/step - loss: 0.6956 - accuracy: 0.5238\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 0s 408us/step - loss: 0.6942 - accuracy: 0.4703\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 0s 402us/step - loss: 0.6924 - accuracy: 0.4746\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 0s 404us/step - loss: 0.6929 - accuracy: 0.4783\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 0s 402us/step - loss: 0.6940 - accuracy: 0.4633\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 0.6939 - accuracy: 0.4655\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 0s 430us/step - loss: 0.6921 - accuracy: 0.4719\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 0s 429us/step - loss: 0.6923 - accuracy: 0.4623\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 0s 417us/step - loss: 0.6934 - accuracy: 0.4623\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 0s 417us/step - loss: 0.6933 - accuracy: 0.4714\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 0s 428us/step - loss: 0.6934 - accuracy: 0.4644\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 0s 462us/step - loss: 0.6932 - accuracy: 0.4746\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 0s 432us/step - loss: 0.6931 - accuracy: 0.4682\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 0s 421us/step - loss: 0.6915 - accuracy: 0.4676\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 0s 412us/step - loss: 0.6902 - accuracy: 0.4848\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 0s 750us/step - loss: 0.6944 - accuracy: 0.4730\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 0s 428us/step - loss: 0.6899 - accuracy: 0.4858\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 0s 429us/step - loss: 0.6920 - accuracy: 0.4799\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 0s 487us/step - loss: 0.6922 - accuracy: 0.4719\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 0s 428us/step - loss: 0.6917 - accuracy: 0.4708\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 0s 433us/step - loss: 0.6931 - accuracy: 0.4741\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 0.6918 - accuracy: 0.4714\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 0s 424us/step - loss: 0.6906 - accuracy: 0.4778\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6914 - accuracy: 0.4741\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 0s 406us/step - loss: 0.6915 - accuracy: 0.4714\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 0s 403us/step - loss: 0.6916 - accuracy: 0.4826\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 0s 412us/step - loss: 0.6918 - accuracy: 0.4794\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 0s 405us/step - loss: 0.6925 - accuracy: 0.4794\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 0s 412us/step - loss: 0.6916 - accuracy: 0.4815\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 0s 425us/step - loss: 0.6923 - accuracy: 0.4708\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 0s 420us/step - loss: 0.6901 - accuracy: 0.4783\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6889 - accuracy: 0.4783\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6924 - accuracy: 0.4714\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6910 - accuracy: 0.4714\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6910 - accuracy: 0.4783\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 0s 419us/step - loss: 0.6876 - accuracy: 0.4896\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 0s 417us/step - loss: 0.6933 - accuracy: 0.4735\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6923 - accuracy: 0.4650\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 0s 419us/step - loss: 0.6916 - accuracy: 0.4714\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 0s 411us/step - loss: 0.6915 - accuracy: 0.4741\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6917 - accuracy: 0.4735\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6897 - accuracy: 0.4730\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6901 - accuracy: 0.4783\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6887 - accuracy: 0.4794\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 0s 410us/step - loss: 0.6911 - accuracy: 0.4708\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 0s 412us/step - loss: 0.6916 - accuracy: 0.4660\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 0s 417us/step - loss: 0.6906 - accuracy: 0.4735\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6905 - accuracy: 0.4794\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6927 - accuracy: 0.4719\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 0s 419us/step - loss: 0.6891 - accuracy: 0.4789\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 0s 411us/step - loss: 0.6889 - accuracy: 0.4757\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 0s 410us/step - loss: 0.6892 - accuracy: 0.4799\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 0s 410us/step - loss: 0.6875 - accuracy: 0.4831\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6906 - accuracy: 0.4724\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6910 - accuracy: 0.4741\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6907 - accuracy: 0.4767\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6896 - accuracy: 0.4837\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 0s 411us/step - loss: 0.6912 - accuracy: 0.4746\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 0s 417us/step - loss: 0.6909 - accuracy: 0.4853\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 0s 415us/step - loss: 0.6916 - accuracy: 0.4724\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6902 - accuracy: 0.4789\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 0s 411us/step - loss: 0.6920 - accuracy: 0.4762\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 0s 408us/step - loss: 0.6883 - accuracy: 0.4831\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6903 - accuracy: 0.4783\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6904 - accuracy: 0.4821\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 0s 416us/step - loss: 0.6889 - accuracy: 0.4853\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 0s 411us/step - loss: 0.6881 - accuracy: 0.4949\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 0s 410us/step - loss: 0.6887 - accuracy: 0.4880\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6872 - accuracy: 0.4890\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 0s 416us/step - loss: 0.6895 - accuracy: 0.5003\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 0s 412us/step - loss: 0.6909 - accuracy: 0.4949\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6882 - accuracy: 0.4885\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6875 - accuracy: 0.4842\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 0s 415us/step - loss: 0.6895 - accuracy: 0.4810\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 0s 410us/step - loss: 0.6902 - accuracy: 0.4783\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 0s 415us/step - loss: 0.6880 - accuracy: 0.4799\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6885 - accuracy: 0.4810\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 0s 420us/step - loss: 0.6892 - accuracy: 0.4965\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 0s 416us/step - loss: 0.6886 - accuracy: 0.4933\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6881 - accuracy: 0.5067\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 0s 417us/step - loss: 0.6880 - accuracy: 0.4922\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 0.6902 - accuracy: 0.4869\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 0s 469us/step - loss: 0.6882 - accuracy: 0.4912\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 0s 428us/step - loss: 0.6880 - accuracy: 0.4880\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 0s 420us/step - loss: 0.6855 - accuracy: 0.5024\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 0s 414us/step - loss: 0.6908 - accuracy: 0.4906\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 0s 413us/step - loss: 0.6880 - accuracy: 0.4896\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 0s 415us/step - loss: 0.6864 - accuracy: 0.4906\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 0s 410us/step - loss: 0.6900 - accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 0s 408us/step - loss: 0.6878 - accuracy: 0.4869\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 0s 430us/step - loss: 0.6882 - accuracy: 0.4906\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 0s 444us/step - loss: 0.6887 - accuracy: 0.4880\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 0.6908 - accuracy: 0.4842\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 0s 416us/step - loss: 0.6876 - accuracy: 0.4944\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 0s 412us/step - loss: 0.6869 - accuracy: 0.4928\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 0s 415us/step - loss: 0.6852 - accuracy: 0.4933\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 0s 415us/step - loss: 0.6888 - accuracy: 0.4976\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 0s 408us/step - loss: 0.6921 - accuracy: 0.4885\n",
      "5/5 [==============================] - 0s 352us/step\n",
      "5/5 [==============================] - 0s 381us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress: 100%|██████████████████████████████ | 43/43 [05:22<00:00] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.5 AUC Score: 0.49635416666666665\n",
      "----------------------------------------\n",
      "Balanced Accuracy: 0.5541666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_splits = len(np.unique(groups))\n",
    "print(num_splits)\n",
    "\n",
    "with tqdm(total=num_splits, desc=\"LOSO CV Progress\", unit=\"fold\", bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {percentage:3.0f}%\") as pbar:\n",
    "    for train_idx, test_idx in logo.split(X, y_encoded, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]  \n",
    "\n",
    "        print('X and y train shapes: ')\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "\n",
    "        train_class_counts = np.bincount(y_train)\n",
    "        print(f\"Train set - Class 0 (Low Stress): {train_class_counts[0]}, \"\n",
    "              f\"Class 1 (High Stress): {train_class_counts[1] if len(train_class_counts) > 1 else 0}\")\n",
    "\n",
    "        test_class_counts = np.bincount(y_test)\n",
    "        print(f\"Test set - Class 0 (Low Stress): {test_class_counts[0]}, \"\n",
    "              f\"Class 1 (High Stress): {test_class_counts[1] if len(test_class_counts) > 1 else 0}\")\n",
    "\n",
    "        print(f\"Test set size: {len(y_test)}\")\n",
    "        print(f\"Train set shape: {X_train.shape}\")\n",
    "        print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_normalized = scaler.fit_transform(X_train)\n",
    "        X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "        print(X_train_normalized.shape)\n",
    "        print(X_test_normalized.shape)\n",
    "\n",
    "        # Define the FCN model\n",
    "        model_fcn_binary_lh = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(57, activation='relu', input_dim=X_train_normalized.shape[1]),\n",
    "            tf.keras.layers.Dropout(0.35),\n",
    "            tf.keras.layers.Dense(35, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.15),\n",
    "            tf.keras.layers.Dense(3, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.15),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "        ])\n",
    "        print('Model Defined')\n",
    "\n",
    "        custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model_fcn_binary_lh.compile(\n",
    "            optimizer=custom_optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']  \n",
    "        )\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        print('Class Weight: ', class_weight_dict)\n",
    "\n",
    "        model_fcn_binary_lh.fit(\n",
    "            X_train_normalized, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1  \n",
    "        )\n",
    "\n",
    "        thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "        y_test_pred_proba = model_fcn_binary_lh.predict(X_test_normalized)\n",
    "\n",
    "        best_threshold = 0.0\n",
    "        best_metric = 0.0\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            y_test_pred_binary = (y_test_pred_proba > threshold).astype(int)\n",
    "            metric_value = balanced_accuracy_score(y_test, y_test_pred_binary)\n",
    "\n",
    "            if metric_value > best_metric:\n",
    "                best_metric = metric_value\n",
    "                best_threshold = threshold\n",
    "\n",
    "        y_test_pred_proba = model_fcn_binary_lh.predict(X_test_normalized)\n",
    "\n",
    "        if len(np.unique(y_test)) > 1:\n",
    "            auc_score = roc_auc_score(y_test, y_test_pred_proba)\n",
    "            auc_scores.append(auc_score)  \n",
    "            if auc_score < 0.5:\n",
    "                print(f\"<0.5 AUC Score: {auc_score}\")\n",
    "                print(\"----------------------------------------\")\n",
    "            else:\n",
    "                print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "        else:\n",
    "            auc_scores.append(None)  \n",
    "            print(f\"Skipping AUC computation for this fold as y_test contains only one class: {np.unique(y_test)}\")\n",
    "\n",
    "        y_test_pred_binary = (y_test_pred_proba > best_threshold).astype(int)\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_test_pred_binary)\n",
    "        balanced_accs.append(balanced_acc) \n",
    "        best_thresholds.append(best_threshold)  \n",
    "        print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa94d59b-4175-43f6-857f-5cdf2488850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP: \n",
      "Median, 25th Percentile, 75th Percentile: \n",
      "AUC Score - Median: 0.5171957671957672, 25th Percentile: 0.4297339188840093, 75th Percentile: 0.572787488201022\n",
      "Balanced Accuracy - Median: 0.564957264957265, 25th Percentile: 0.5267094017094017, 75th Percentile: 0.6597222222222222\n"
     ]
    }
   ],
   "source": [
    "print('MLP: ')\n",
    "print('Median, 25th Percentile, 75th Percentile: ')\n",
    "\n",
    "if auc_scores:\n",
    "    auc_scores_valid = [score for score in auc_scores if score is not None] \n",
    "\n",
    "    auc_median = np.median(auc_scores_valid)\n",
    "    auc_25_percentile = np.percentile(auc_scores_valid, 25)\n",
    "    auc_75_percentile = np.percentile(auc_scores_valid, 75)\n",
    "    print(f\"AUC Score - Median: {auc_median}, 25th Percentile: {auc_25_percentile}, 75th Percentile: {auc_75_percentile}\")\n",
    "\n",
    "balanced_acc_median = np.median(balanced_accs)\n",
    "balanced_acc_25_percentile = np.percentile(balanced_accs, 25)\n",
    "balanced_acc_75_percentile = np.percentile(balanced_accs, 75)\n",
    "\n",
    "print(f\"Balanced Accuracy - Median: {balanced_acc_median}, 25th Percentile: {balanced_acc_25_percentile}, 75th Percentile: {balanced_acc_75_percentile}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
