{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89fb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from itertools import combinations\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13de8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/ohidabinteamin/Documents/Stress Prediction Project Three Datasets/StudentLife/week 01/Social_Interaction/recreating_social_features_studentlife.csv')\n",
    "df1 = df1.rename(columns={'Date': 'date'})\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df2 = pd.read_csv('/Users/ohidabinteamin/Documents/Stress Prediction Project Three Datasets/StudentLife/week 01/Stress/recreating_dailystress_features.csv')\n",
    "df2 = df2.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8790dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'uid', 'date', 'app usage in morning',\n",
      "       'app usage in afternoon', 'app usage in evening', 'app usage in night',\n",
      "       'number of call in morning', 'number of call in afternoon',\n",
      "       'number of call in evening', 'number of call in night',\n",
      "       'number of Bluetooth contacts morning',\n",
      "       'number of Bluetooth contacts afternoon',\n",
      "       'number of Bluetooth contacts evening',\n",
      "       'number of Bluetooth contacts night', 'conversation in morning',\n",
      "       'conversation in afternoon', 'conversation in evening',\n",
      "       'conversation in night', 'stress_ratings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df1, df2, on=['uid', 'date'])\n",
    "print(df.columns)\n",
    "\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88641721-82da-42c7-b187-a673a82f011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                              0\n",
       "uid                                       0\n",
       "date                                      0\n",
       "app usage in morning                      0\n",
       "app usage in afternoon                    0\n",
       "app usage in evening                      0\n",
       "app usage in night                        0\n",
       "number of call in morning                 0\n",
       "number of call in afternoon               0\n",
       "number of call in evening                 0\n",
       "number of call in night                   0\n",
       "number of Bluetooth contacts morning      0\n",
       "number of Bluetooth contacts afternoon    0\n",
       "number of Bluetooth contacts evening      0\n",
       "number of Bluetooth contacts night        0\n",
       "conversation in morning                   0\n",
       "conversation in afternoon                 0\n",
       "conversation in evening                   0\n",
       "conversation in night                     0\n",
       "stress_ratings                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576bb6e1-ad0a-4d6c-9768-5a7a30b1dfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2f78a1-7383-4c8c-846c-06763e97ab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'uid', 'date', 'app usage in morning',\n",
       "       'app usage in afternoon', 'app usage in evening', 'app usage in night',\n",
       "       'number of call in morning', 'number of call in afternoon',\n",
       "       'number of call in evening', 'number of call in night',\n",
       "       'number of Bluetooth contacts morning',\n",
       "       'number of Bluetooth contacts afternoon',\n",
       "       'number of Bluetooth contacts evening',\n",
       "       'number of Bluetooth contacts night', 'conversation in morning',\n",
       "       'conversation in afternoon', 'conversation in evening',\n",
       "       'conversation in night', 'stress_ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5032380-a9b2-4dc8-b42d-3e3a5b632093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637f66c7-2809-40a4-abc0-702c72e594a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stress_ratings\n",
       "medium stress    193\n",
       "high stress      162\n",
       "low stress       140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stress_ratings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05191acb-7624-4e48-9767-a3052e486aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lh_data = df[df['stress_ratings'].isin(['low stress', 'high stress'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6d94cc-584a-45ee-b3b8-3d3eaab2c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "uid\n",
       "u59    51\n",
       "u49    27\n",
       "u57    24\n",
       "u58    21\n",
       "u08    21\n",
       "u00    20\n",
       "u52    20\n",
       "u46    18\n",
       "u12    14\n",
       "u02    13\n",
       "u51    13\n",
       "u56    12\n",
       "u24    11\n",
       "u53    11\n",
       "u36     9\n",
       "u54     7\n",
       "u31     5\n",
       "u47     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(binary_lh_data['uid'].unique()))\n",
    "binary_lh_data['uid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373c5b85-dffb-4d9b-a342-65e2525f9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uid_counts = binary_lh_data['uid'].value_counts()\n",
    "# uids_to_keep = uid_counts[uid_counts >= 5].index\n",
    "# binary_lh_data = binary_lh_data[binary_lh_data['uid'].isin(uids_to_keep)]\n",
    "\n",
    "# print('Length of Data: ', len(binary_lh_data))\n",
    "# binary_lh_data = binary_lh_data.sort_values(by=['uid', 'date'])\n",
    "# print(binary_lh_data['uid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3a31f1-a8e0-4bba-8ef1-d18f29836618",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = binary_lh_data.drop(columns=['stress_ratings', 'uid', 'date'])\n",
    "y = binary_lh_data['stress_ratings']\n",
    "groups = binary_lh_data['uid']\n",
    "\n",
    "stress_map = {'low stress': 0, 'high stress': 1}\n",
    "y_encoded = y.map(stress_map).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7a26eb-d08f-4420-ad6c-061e2e766686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in X: 17\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features in X: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d30d3ea7-b395-4fcf-ad12-0d03a5fecbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "best_thresholds = []\n",
    "balanced_accs = []\n",
    "auc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "561f903a-6aef-4e34-b406-93ca30bbd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e0b5eb-50c0-48f6-a1a7-eaa67bbfbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'penalty': ['l2'],\n",
    "     'solver': ['newton-cg', 'lbfgs', 'sag']},\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear']},\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'l1_ratio': [0.2, 0.5, 0.8],\n",
    "     'penalty': ['elasticnet'],\n",
    "     'solver': ['saga']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2be34cb-e293-4beb-828f-71af3e289fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [ 0  2  3  4  5  6  8  9 10 11 12 13 14 15 16]\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:   0%|                                    | 0/18 [00:00<?]   0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y train shapes: \n",
      "(282, 15)\n",
      "(282,)\n",
      "X and y test shapes: \n",
      "(20, 15)\n",
      "(20,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  11%|███▍                            | 2/18 [00:00<00:06]  11%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.13131313131313133\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(289, 15)\n",
      "(289,)\n",
      "X and y test shapes: \n",
      "(13, 15)\n",
      "(13,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.7000000000000001\n",
      "Balanced Accuracy: 0.7\n",
      "X and y train shapes: \n",
      "(281, 15)\n",
      "(281,)\n",
      "X and y test shapes: \n",
      "(21, 15)\n",
      "(21,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  22%|██████▉                         | 4/18 [00:01<00:02]  22%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.34444444444444444\n",
      "Balanced Accuracy: 0.5833333333333334\n",
      "X and y train shapes: \n",
      "(288, 15)\n",
      "(288,)\n",
      "X and y test shapes: \n",
      "(14, 15)\n",
      "(14,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.6041666666666667\n",
      "Balanced Accuracy: 0.5833333333333334\n",
      "X and y train shapes: \n",
      "(291, 15)\n",
      "(291,)\n",
      "X and y test shapes: \n",
      "(11, 15)\n",
      "(11,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.2777777777777778\n",
      "Balanced Accuracy: 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  39%|████████████                    | 7/18 [00:01<00:01]  39%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y train shapes: \n",
      "(297, 15)\n",
      "(297,)\n",
      "X and y test shapes: \n",
      "(5, 15)\n",
      "(5,)\n",
      "Skipping this subject for having single class: y_train = [0 1], y_test = [0]\n",
      "X and y train shapes: \n",
      "(293, 15)\n",
      "(293,)\n",
      "X and y test shapes: \n",
      "(9, 15)\n",
      "(9,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.07142857142857142\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(284, 15)\n",
      "(284,)\n",
      "X and y test shapes: \n",
      "(18, 15)\n",
      "(18,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  50%|███████████████▌                | 9/18 [00:01<00:01]  50%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.725\n",
      "Balanced Accuracy: 0.7\n",
      "X and y train shapes: \n",
      "(297, 15)\n",
      "(297,)\n",
      "X and y test shapes: \n",
      "(5, 15)\n",
      "(5,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.5\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(275, 15)\n",
      "(275,)\n",
      "X and y test shapes: \n",
      "(27, 15)\n",
      "(27,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.6111111111111112\n",
      "Balanced Accuracy: 0.6388888888888888\n",
      "X and y train shapes: \n",
      "(289, 15)\n",
      "(289,)\n",
      "X and y test shapes: \n",
      "(13, 15)\n",
      "(13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  61%|██████████████████▎            | 11/18 [00:01<00:00]  61%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.8333333333333334\n",
      "Balanced Accuracy: 0.5\n",
      "X and y train shapes: \n",
      "(282, 15)\n",
      "(282,)\n",
      "X and y test shapes: \n",
      "(20, 15)\n",
      "(20,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  72%|█████████████████████▋         | 13/18 [00:02<00:00]  72%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6875\n",
      "Balanced Accuracy: 0.5833333333333334\n",
      "X and y train shapes: \n",
      "(291, 15)\n",
      "(291,)\n",
      "X and y test shapes: \n",
      "(11, 15)\n",
      "(11,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.4444444444444444\n",
      "Balanced Accuracy: 0.6666666666666666\n",
      "X and y train shapes: \n",
      "(295, 15)\n",
      "(295,)\n",
      "X and y test shapes: \n",
      "(7, 15)\n",
      "(7,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.25\n",
      "Balanced Accuracy: 0.5416666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  83%|█████████████████████████      | 15/18 [00:02<00:00]  83%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y train shapes: \n",
      "(290, 15)\n",
      "(290,)\n",
      "X and y test shapes: \n",
      "(12, 15)\n",
      "(12,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.4857142857142857\n",
      "Balanced Accuracy: 0.5285714285714286\n",
      "X and y train shapes: \n",
      "(278, 15)\n",
      "(278,)\n",
      "X and y test shapes: \n",
      "(24, 15)\n",
      "(24,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress:  94%|████████████████████████████▎  | 17/18 [00:02<00:00]  94%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6302521008403361\n",
      "Balanced Accuracy: 0.5798319327731092\n",
      "X and y train shapes: \n",
      "(281, 15)\n",
      "(281,)\n",
      "X and y test shapes: \n",
      "(21, 15)\n",
      "(21,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.625\n",
      "Balanced Accuracy: 0.7\n",
      "X and y train shapes: \n",
      "(251, 15)\n",
      "(251,)\n",
      "X and y test shapes: \n",
      "(51, 15)\n",
      "(51,)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "AUC Score: 0.6204545454545455\n",
      "Balanced Accuracy: 0.5943181818181817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSO CV Progress: 100%|██████████████████████████████ | 18/18 [00:02<00:00] 100%\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model_logistic_rfe = LogisticRegression(max_iter=5000)\n",
    "\n",
    "rfe = RFE(model_logistic_rfe, n_features_to_select=15)  \n",
    "X_ = scaler.fit_transform(X)\n",
    "rfe.fit(X_, y_encoded) \n",
    "\n",
    "best_features = np.where(rfe.support_)[0]\n",
    "print(f\"Selected Features: {best_features}\")\n",
    "\n",
    "num_splits = len(np.unique(groups))\n",
    "print(num_splits)\n",
    "\n",
    "with tqdm(total=num_splits, desc=\"LOSO CV Progress\", unit=\"fold\", bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {percentage:3.0f}%\") as pbar:\n",
    "    for train_idx, test_idx in logo.split(X, y_encoded, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx, best_features], X.iloc[test_idx, best_features]\n",
    "        y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "        print('X and y train shapes: ')\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "\n",
    "        print('X and y test shapes: ')\n",
    "        print(X_test.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_normalized = scaler.fit_transform(X_train)\n",
    "        X_test_normalized = scaler.transform(X_test)\n",
    "        \n",
    "        model_logistic = GridSearchCV(LogisticRegression(max_iter=5000, class_weight='balanced'),\n",
    "                                      param_grid=param_grid, cv=3, verbose=True, n_jobs=-1, scoring='roc_auc')\n",
    "        if len(np.unique(y_train)) > 1 and len(np.unique(y_test)) > 1:\n",
    "            model_logistic.fit(X_train_normalized, y_train)\n",
    "    \n",
    "            y_test_pred_proba = model_logistic.predict_proba(X_test_normalized)[:, 1]\n",
    "            thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "            best_threshold = 0.5\n",
    "            best_metric = 0.0\n",
    "    \n",
    "            for threshold in thresholds:\n",
    "                y_test_pred_binary = (y_test_pred_proba > threshold).astype(int)\n",
    "                metric_value = balanced_accuracy_score(y_test, y_test_pred_binary)\n",
    "                if metric_value > best_metric:\n",
    "                    best_metric = metric_value\n",
    "                    best_threshold = threshold\n",
    "            if len(np.unique(y_test)) > 1:\n",
    "                auc_score = roc_auc_score(y_test, y_test_pred_proba)\n",
    "                auc_scores.append(auc_score)\n",
    "                print(f\"AUC Score: {auc_score}\")\n",
    "            else:\n",
    "                auc_scores.append(None)\n",
    "                print(f\"Skipping AUC computation for this fold as y_test contains only one class: {np.unique(y_test)}\")\n",
    "    \n",
    "            y_test_pred_binary = (y_test_pred_proba > best_threshold).astype(int)\n",
    "            balanced_acc = balanced_accuracy_score(y_test, y_test_pred_binary)\n",
    "            balanced_accs.append(balanced_acc)\n",
    "        \n",
    "            print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping this subject for having single class: y_train = {np.unique(y_train)}, y_test = {np.unique(y_test)}\")\n",
    "        \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa94d59b-4175-43f6-857f-5cdf2488850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "Median, 25th Percentile, 75th Percentile: \n",
      "AUC Score - Median: 0.6042, 25th Percentile: 0.3444, 75th Percentile: 0.6303\n",
      "Balanced Accuracy - Median: 0.5833, 25th Percentile: 0.5286, 75th Percentile: 0.6389\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression: ')\n",
    "print('Median, 25th Percentile, 75th Percentile: ')\n",
    "\n",
    "if auc_scores:\n",
    "    auc_scores_valid = [score for score in auc_scores if score is not None] \n",
    "\n",
    "    auc_median = np.median(auc_scores_valid)\n",
    "    auc_25_percentile = np.percentile(auc_scores_valid, 25)\n",
    "    auc_75_percentile = np.percentile(auc_scores_valid, 75)\n",
    "    print(f\"AUC Score - Median: {auc_median:.4f}, 25th Percentile: {auc_25_percentile:.4f}, 75th Percentile: {auc_75_percentile:.4f}\")\n",
    "\n",
    "balanced_accs_valid = [acc for acc in balanced_accs if acc is not None] \n",
    "\n",
    "balanced_acc_median = np.median(balanced_accs)\n",
    "balanced_acc_25_percentile = np.percentile(balanced_accs, 25)\n",
    "balanced_acc_75_percentile = np.percentile(balanced_accs, 75)\n",
    "\n",
    "print(f\"Balanced Accuracy - Median: {balanced_acc_median:.4f}, 25th Percentile: {balanced_acc_25_percentile:.4f}, 75th Percentile: {balanced_acc_75_percentile:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2c86d-c7a0-45e9-bb43-d3536e223db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
